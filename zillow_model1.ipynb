{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Zillow Sales versus List prices weekly for major US cities"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "# Loading in the basics\r\n",
    "import psycopg2\r\n",
    "from sklearn.neural_network import MLPRegressor\r\n",
    "from sklearn.ensemble import RandomForestRegressor\r\n",
    "from sklearn.linear_model import LinearRegression\r\n",
    "from sklearn.neighbors import KNeighborsRegressor\r\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\r\n",
    "from sklearn.svm import SVR\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import tensorflow as tf\r\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "# Connect to postgres db\r\n",
    "ENDPOINT=\"ucb-data-group-project-zillow.csaw135fqqkl.us-west-1.rds.amazonaws.com\"\r\n",
    "PORT=\"5432\"\r\n",
    "USR=\"postgres\"\r\n",
    "REGION=\"us-west-1\"\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "DBNAME=\"postgres\"\r\n",
    "\r\n",
    "conn = psycopg2.connect(database = DBNAME,\r\n",
    "                        user =     USR,\r\n",
    "                        password = \"aldavidethanjohn\",\r\n",
    "                        host =     ENDPOINT,\r\n",
    "                        port =     PORT)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "# list table sql\r\n",
    "list_sql = '''\r\n",
    "            SELECT *\r\n",
    "            FROM list;\r\n",
    "            '''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "# sale table sql\r\n",
    "sale_sql = '''\r\n",
    "            SELECT *\r\n",
    "            FROM sale;\r\n",
    "            '''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "# setting up dfs\r\n",
    "list_df = pd.read_sql(list_sql, conn)\r\n",
    "sale_df = pd.read_sql(sale_sql, conn)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "# inspect list df\r\n",
    "list_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      region_date region_id  size_rank                         region_name  \\\n",
       "0  10200120171104    102001          0                       United States   \n",
       "1  39491320171104    394913          1                        New York, NY   \n",
       "2  75389920171104    753899          2  Los Angeles-Long Beach-Anaheim, CA   \n",
       "3  39446320171104    394463          3                         Chicago, IL   \n",
       "4  39451420171104    394514          4               Dallas-Fort Worth, TX   \n",
       "\n",
       "  region_type state_name        date     price  \n",
       "0     Country       None  2017-11-04  275448.0  \n",
       "1         Msa         NY  2017-11-04  526850.0  \n",
       "2         Msa         CA  2017-11-04  812252.0  \n",
       "3         Msa         IL  2017-11-04  319556.0  \n",
       "4         Msa         TX  2017-11-04  347537.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region_date</th>\n",
       "      <th>region_id</th>\n",
       "      <th>size_rank</th>\n",
       "      <th>region_name</th>\n",
       "      <th>region_type</th>\n",
       "      <th>state_name</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10200120171104</td>\n",
       "      <td>102001</td>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Country</td>\n",
       "      <td>None</td>\n",
       "      <td>2017-11-04</td>\n",
       "      <td>275448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39491320171104</td>\n",
       "      <td>394913</td>\n",
       "      <td>1</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Msa</td>\n",
       "      <td>NY</td>\n",
       "      <td>2017-11-04</td>\n",
       "      <td>526850.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75389920171104</td>\n",
       "      <td>753899</td>\n",
       "      <td>2</td>\n",
       "      <td>Los Angeles-Long Beach-Anaheim, CA</td>\n",
       "      <td>Msa</td>\n",
       "      <td>CA</td>\n",
       "      <td>2017-11-04</td>\n",
       "      <td>812252.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39446320171104</td>\n",
       "      <td>394463</td>\n",
       "      <td>3</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Msa</td>\n",
       "      <td>IL</td>\n",
       "      <td>2017-11-04</td>\n",
       "      <td>319556.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39451420171104</td>\n",
       "      <td>394514</td>\n",
       "      <td>4</td>\n",
       "      <td>Dallas-Fort Worth, TX</td>\n",
       "      <td>Msa</td>\n",
       "      <td>TX</td>\n",
       "      <td>2017-11-04</td>\n",
       "      <td>347537.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "# inspect sale df\r\n",
    "sale_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      region_date region_id  size_rank                         region_name  \\\n",
       "0  10200120080223    102001          0                       United States   \n",
       "1  39491320080223    394913          1                        New York, NY   \n",
       "2  75389920080223    753899          2  Los Angeles-Long Beach-Anaheim, CA   \n",
       "3  39446320080223    394463          3                         Chicago, IL   \n",
       "4  39451420080223    394514          4               Dallas-Fort Worth, TX   \n",
       "\n",
       "  region_type state_name        date     price  \n",
       "0     Country       None  2008-02-23  191138.0  \n",
       "1         Msa         NY  2008-02-23       NaN  \n",
       "2         Msa         CA  2008-02-23  516750.0  \n",
       "3         Msa         IL  2008-02-23  247988.0  \n",
       "4         Msa         TX  2008-02-23  143466.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region_date</th>\n",
       "      <th>region_id</th>\n",
       "      <th>size_rank</th>\n",
       "      <th>region_name</th>\n",
       "      <th>region_type</th>\n",
       "      <th>state_name</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10200120080223</td>\n",
       "      <td>102001</td>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Country</td>\n",
       "      <td>None</td>\n",
       "      <td>2008-02-23</td>\n",
       "      <td>191138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39491320080223</td>\n",
       "      <td>394913</td>\n",
       "      <td>1</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Msa</td>\n",
       "      <td>NY</td>\n",
       "      <td>2008-02-23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75389920080223</td>\n",
       "      <td>753899</td>\n",
       "      <td>2</td>\n",
       "      <td>Los Angeles-Long Beach-Anaheim, CA</td>\n",
       "      <td>Msa</td>\n",
       "      <td>CA</td>\n",
       "      <td>2008-02-23</td>\n",
       "      <td>516750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39446320080223</td>\n",
       "      <td>394463</td>\n",
       "      <td>3</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Msa</td>\n",
       "      <td>IL</td>\n",
       "      <td>2008-02-23</td>\n",
       "      <td>247988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39451420080223</td>\n",
       "      <td>394514</td>\n",
       "      <td>4</td>\n",
       "      <td>Dallas-Fort Worth, TX</td>\n",
       "      <td>Msa</td>\n",
       "      <td>TX</td>\n",
       "      <td>2008-02-23</td>\n",
       "      <td>143466.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "# general cleaning\r\n",
    "sale_df = sale_df.drop([\"region_date\",\"region_id\",\"region_type\"],1)\r\n",
    "list_df = list_df.drop([\"region_date\",\"region_id\", \"region_type\"],1)\r\n",
    "list_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   size_rank                         region_name state_name        date  \\\n",
       "0          0                       United States       None  2017-11-04   \n",
       "1          1                        New York, NY         NY  2017-11-04   \n",
       "2          2  Los Angeles-Long Beach-Anaheim, CA         CA  2017-11-04   \n",
       "3          3                         Chicago, IL         IL  2017-11-04   \n",
       "4          4               Dallas-Fort Worth, TX         TX  2017-11-04   \n",
       "\n",
       "      price  \n",
       "0  275448.0  \n",
       "1  526850.0  \n",
       "2  812252.0  \n",
       "3  319556.0  \n",
       "4  347537.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_rank</th>\n",
       "      <th>region_name</th>\n",
       "      <th>state_name</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>2017-11-04</td>\n",
       "      <td>275448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>2017-11-04</td>\n",
       "      <td>526850.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Los Angeles-Long Beach-Anaheim, CA</td>\n",
       "      <td>CA</td>\n",
       "      <td>2017-11-04</td>\n",
       "      <td>812252.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>IL</td>\n",
       "      <td>2017-11-04</td>\n",
       "      <td>319556.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Dallas-Fort Worth, TX</td>\n",
       "      <td>TX</td>\n",
       "      <td>2017-11-04</td>\n",
       "      <td>347537.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "# us data pullout for list and sales data\r\n",
    "\r\n",
    "us_list = list_df.loc[list_df[\"region_name\"] == \"United States\"]\r\n",
    "us_list = us_list.drop([\"size_rank\", \"state_name\"], 1)\r\n",
    "us_sale = sale_df.loc[sale_df[\"region_name\"] == \"United States\"]\r\n",
    "us_sale = us_sale.drop([\"size_rank\", \"state_name\"],1)\r\n",
    "\r\n",
    "us_sale.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       region_name        date     price\n",
       "0    United States  2008-02-23  191138.0\n",
       "128  United States  2020-10-31  290550.0\n",
       "199  United States  2008-03-01  192225.0\n",
       "296  United States  2008-03-08  192225.0\n",
       "393  United States  2008-03-15  192475.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region_name</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "      <td>2008-02-23</td>\n",
       "      <td>191138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>United States</td>\n",
       "      <td>2020-10-31</td>\n",
       "      <td>290550.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>United States</td>\n",
       "      <td>2008-03-01</td>\n",
       "      <td>192225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>United States</td>\n",
       "      <td>2008-03-08</td>\n",
       "      <td>192225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>United States</td>\n",
       "      <td>2008-03-15</td>\n",
       "      <td>192475.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "# prepping us dfs for merge and merging\r\n",
    "us_list = us_list.rename(columns = {\"price\":\"list price\"})\r\n",
    "us_sale = us_sale.rename(columns = {\"price\":\"sale price\"})\r\n",
    "\r\n",
    "us_df = us_list.merge(us_sale, on = [\"region_name\",\"date\"], how = \"right\")\r\n",
    "us_df = us_df.dropna()\r\n",
    "# confirming date is datetime and using date as index\r\n",
    "us_df[\"date\"] = pd.to_datetime(us_df[\"date\"])\r\n",
    "us_df = us_df.set_index(\"date\").sort_index()\r\n",
    "us_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              region_name  list price  sale price\n",
       "date                                             \n",
       "2017-11-04  United States    275448.0    235099.0\n",
       "2017-11-11  United States    275448.0    234750.0\n",
       "2017-11-18  United States    275448.0    235750.0\n",
       "2017-11-25  United States    274975.0    235916.0\n",
       "2017-12-02  United States    274825.0    237166.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region_name</th>\n",
       "      <th>list price</th>\n",
       "      <th>sale price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-04</th>\n",
       "      <td>United States</td>\n",
       "      <td>275448.0</td>\n",
       "      <td>235099.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11</th>\n",
       "      <td>United States</td>\n",
       "      <td>275448.0</td>\n",
       "      <td>234750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-18</th>\n",
       "      <td>United States</td>\n",
       "      <td>275448.0</td>\n",
       "      <td>235750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-25</th>\n",
       "      <td>United States</td>\n",
       "      <td>274975.0</td>\n",
       "      <td>235916.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-02</th>\n",
       "      <td>United States</td>\n",
       "      <td>274825.0</td>\n",
       "      <td>237166.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "us_df.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(186, 5)"
      ]
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "us_df[\"list/sale percent diff\"] = (us_df[\"list price\"] / us_df[\"sale price\"]) * 100\r\n",
    "us_df[\"list/sale actual diff\"] = (us_df[\"list price\"] - us_df[\"sale price\"])\r\n",
    "us_df.drop_duplicates\r\n",
    "us_df.shape\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(186, 5)"
      ]
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "# examining the relation between list and sale\r\n",
    "us_df[\"list/sale percent diff\"].plot(x= \"date\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='date'>"
      ]
     },
     "metadata": {},
     "execution_count": 75
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"273.394063pt\" version=\"1.1\" viewBox=\"0 0 375.2875 273.394063\" width=\"375.2875pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-08-08T15:18:00.700562</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 273.394063 \r\nL 375.2875 273.394063 \r\nL 375.2875 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 33.2875 224.64 \r\nL 368.0875 224.64 \r\nL 368.0875 7.2 \r\nL 33.2875 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"me21551fec7\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#me21551fec7\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"49.575068\" xlink:href=\"#me21551fec7\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- Jan -->\r\n      <g transform=\"translate(41.867255 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 9.8125 72.90625 \r\nL 19.671875 72.90625 \r\nL 19.671875 5.078125 \r\nQ 19.671875 -8.109375 14.671875 -14.0625 \r\nQ 9.671875 -20.015625 -1.421875 -20.015625 \r\nL -5.171875 -20.015625 \r\nL -5.171875 -11.71875 \r\nL -2.09375 -11.71875 \r\nQ 4.4375 -11.71875 7.125 -8.046875 \r\nQ 9.8125 -4.390625 9.8125 5.078125 \r\nz\r\n\" id=\"DejaVuSans-74\"/>\r\n        <path d=\"M 34.28125 27.484375 \r\nQ 23.390625 27.484375 19.1875 25 \r\nQ 14.984375 22.515625 14.984375 16.5 \r\nQ 14.984375 11.71875 18.140625 8.90625 \r\nQ 21.296875 6.109375 26.703125 6.109375 \r\nQ 34.1875 6.109375 38.703125 11.40625 \r\nQ 43.21875 16.703125 43.21875 25.484375 \r\nL 43.21875 27.484375 \r\nz\r\nM 52.203125 31.203125 \r\nL 52.203125 0 \r\nL 43.21875 0 \r\nL 43.21875 8.296875 \r\nQ 40.140625 3.328125 35.546875 0.953125 \r\nQ 30.953125 -1.421875 24.3125 -1.421875 \r\nQ 15.921875 -1.421875 10.953125 3.296875 \r\nQ 6 8.015625 6 15.921875 \r\nQ 6 25.140625 12.171875 29.828125 \r\nQ 18.359375 34.515625 30.609375 34.515625 \r\nL 43.21875 34.515625 \r\nL 43.21875 35.40625 \r\nQ 43.21875 41.609375 39.140625 45 \r\nQ 35.0625 48.390625 27.6875 48.390625 \r\nQ 23 48.390625 18.546875 47.265625 \r\nQ 14.109375 46.140625 10.015625 43.890625 \r\nL 10.015625 52.203125 \r\nQ 14.9375 54.109375 19.578125 55.046875 \r\nQ 24.21875 56 28.609375 56 \r\nQ 40.484375 56 46.34375 49.84375 \r\nQ 52.203125 43.703125 52.203125 31.203125 \r\nz\r\n\" id=\"DejaVuSans-97\"/>\r\n        <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-110\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-74\"/>\r\n       <use x=\"29.492188\" xlink:href=\"#DejaVuSans-97\"/>\r\n       <use x=\"90.771484\" xlink:href=\"#DejaVuSans-110\"/>\r\n      </g>\r\n      <!-- 2018 -->\r\n      <g transform=\"translate(36.850068 250.43625)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n        <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n        <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n        <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-56\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"143.681014\" xlink:href=\"#me21551fec7\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- Jan -->\r\n      <g transform=\"translate(135.973201 239.238438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-74\"/>\r\n       <use x=\"29.492188\" xlink:href=\"#DejaVuSans-97\"/>\r\n       <use x=\"90.771484\" xlink:href=\"#DejaVuSans-110\"/>\r\n      </g>\r\n      <!-- 2019 -->\r\n      <g transform=\"translate(130.956014 250.43625)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.984375 1.515625 \r\nL 10.984375 10.5 \r\nQ 14.703125 8.734375 18.5 7.8125 \r\nQ 22.3125 6.890625 25.984375 6.890625 \r\nQ 35.75 6.890625 40.890625 13.453125 \r\nQ 46.046875 20.015625 46.78125 33.40625 \r\nQ 43.953125 29.203125 39.59375 26.953125 \r\nQ 35.25 24.703125 29.984375 24.703125 \r\nQ 19.046875 24.703125 12.671875 31.3125 \r\nQ 6.296875 37.9375 6.296875 49.421875 \r\nQ 6.296875 60.640625 12.9375 67.421875 \r\nQ 19.578125 74.21875 30.609375 74.21875 \r\nQ 43.265625 74.21875 49.921875 64.515625 \r\nQ 56.59375 54.828125 56.59375 36.375 \r\nQ 56.59375 19.140625 48.40625 8.859375 \r\nQ 40.234375 -1.421875 26.421875 -1.421875 \r\nQ 22.703125 -1.421875 18.890625 -0.6875 \r\nQ 15.09375 0.046875 10.984375 1.515625 \r\nz\r\nM 30.609375 32.421875 \r\nQ 37.25 32.421875 41.125 36.953125 \r\nQ 45.015625 41.5 45.015625 49.421875 \r\nQ 45.015625 57.28125 41.125 61.84375 \r\nQ 37.25 66.40625 30.609375 66.40625 \r\nQ 23.96875 66.40625 20.09375 61.84375 \r\nQ 16.21875 57.28125 16.21875 49.421875 \r\nQ 16.21875 41.5 20.09375 36.953125 \r\nQ 23.96875 32.421875 30.609375 32.421875 \r\nz\r\n\" id=\"DejaVuSans-57\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-57\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"237.786959\" xlink:href=\"#me21551fec7\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- Jan -->\r\n      <g transform=\"translate(230.079147 239.238438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-74\"/>\r\n       <use x=\"29.492188\" xlink:href=\"#DejaVuSans-97\"/>\r\n       <use x=\"90.771484\" xlink:href=\"#DejaVuSans-110\"/>\r\n      </g>\r\n      <!-- 2020 -->\r\n      <g transform=\"translate(225.061959 250.43625)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"331.892905\" xlink:href=\"#me21551fec7\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- Jan -->\r\n      <g transform=\"translate(324.185093 239.238438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-74\"/>\r\n       <use x=\"29.492188\" xlink:href=\"#DejaVuSans-97\"/>\r\n       <use x=\"90.771484\" xlink:href=\"#DejaVuSans-110\"/>\r\n      </g>\r\n      <!-- 2021 -->\r\n      <g transform=\"translate(319.167905 250.43625)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-49\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"368.0875\" xlink:href=\"#me21551fec7\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 2 \r\n\" id=\"mf34fff8b57\" style=\"stroke:#000000;stroke-width:0.6;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"40.526419\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_8\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"56.813986\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_9\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"64.052905\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_10\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"73.101554\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_11\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"80.340473\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_12\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"87.579392\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_13\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"96.628041\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- Jul -->\r\n      <g transform=\"translate(90.595228 237.638438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 8.5 21.578125 \r\nL 8.5 54.6875 \r\nL 17.484375 54.6875 \r\nL 17.484375 21.921875 \r\nQ 17.484375 14.15625 20.5 10.265625 \r\nQ 23.53125 6.390625 29.59375 6.390625 \r\nQ 36.859375 6.390625 41.078125 11.03125 \r\nQ 45.3125 15.671875 45.3125 23.6875 \r\nL 45.3125 54.6875 \r\nL 54.296875 54.6875 \r\nL 54.296875 0 \r\nL 45.3125 0 \r\nL 45.3125 8.40625 \r\nQ 42.046875 3.421875 37.71875 1 \r\nQ 33.40625 -1.421875 27.6875 -1.421875 \r\nQ 18.265625 -1.421875 13.375 4.4375 \r\nQ 8.5 10.296875 8.5 21.578125 \r\nz\r\nM 31.109375 56 \r\nz\r\n\" id=\"DejaVuSans-117\"/>\r\n        <path d=\"M 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\n\" id=\"DejaVuSans-108\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-74\"/>\r\n       <use x=\"29.492188\" xlink:href=\"#DejaVuSans-117\"/>\r\n       <use x=\"92.871094\" xlink:href=\"#DejaVuSans-108\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_14\">\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"103.866959\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_15\">\r\n     <g id=\"line2d_15\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"111.105878\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_16\">\r\n     <g id=\"line2d_16\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"120.154527\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_17\">\r\n     <g id=\"line2d_17\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"127.393446\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_18\">\r\n     <g id=\"line2d_18\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"134.632365\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_19\">\r\n     <g id=\"line2d_19\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"150.919932\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_20\">\r\n     <g id=\"line2d_20\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"158.158851\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_21\">\r\n     <g id=\"line2d_21\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"167.2075\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_22\">\r\n     <g id=\"line2d_22\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"174.446419\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_23\">\r\n     <g id=\"line2d_23\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"181.685338\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_24\">\r\n     <g id=\"line2d_24\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"190.733986\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- Jul -->\r\n      <g transform=\"translate(184.701174 237.638438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-74\"/>\r\n       <use x=\"29.492188\" xlink:href=\"#DejaVuSans-117\"/>\r\n       <use x=\"92.871094\" xlink:href=\"#DejaVuSans-108\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_25\">\r\n     <g id=\"line2d_25\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"197.972905\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_26\">\r\n     <g id=\"line2d_26\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"207.021554\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_27\">\r\n     <g id=\"line2d_27\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"214.260473\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_28\">\r\n     <g id=\"line2d_28\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"221.499392\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_29\">\r\n     <g id=\"line2d_29\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"230.548041\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_30\">\r\n     <g id=\"line2d_30\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"245.025878\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_31\">\r\n     <g id=\"line2d_31\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"254.074527\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_32\">\r\n     <g id=\"line2d_32\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"261.313446\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_33\">\r\n     <g id=\"line2d_33\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"268.552365\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_34\">\r\n     <g id=\"line2d_34\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"277.601014\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_35\">\r\n     <g id=\"line2d_35\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"284.839932\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- Jul -->\r\n      <g transform=\"translate(278.80712 237.638438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-74\"/>\r\n       <use x=\"29.492188\" xlink:href=\"#DejaVuSans-117\"/>\r\n       <use x=\"92.871094\" xlink:href=\"#DejaVuSans-108\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_36\">\r\n     <g id=\"line2d_36\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"292.078851\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_37\">\r\n     <g id=\"line2d_37\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"301.1275\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_38\">\r\n     <g id=\"line2d_38\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"308.366419\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_39\">\r\n     <g id=\"line2d_39\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"317.415068\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_40\">\r\n     <g id=\"line2d_40\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"324.653986\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_41\">\r\n     <g id=\"line2d_41\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"340.941554\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_42\">\r\n     <g id=\"line2d_42\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"348.180473\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_43\">\r\n     <g id=\"line2d_43\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"355.419392\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_44\">\r\n     <g id=\"line2d_44\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"362.658311\" xlink:href=\"#mf34fff8b57\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_8\">\r\n     <!-- date -->\r\n     <g transform=\"translate(189.4125 264.114375)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 45.40625 46.390625 \r\nL 45.40625 75.984375 \r\nL 54.390625 75.984375 \r\nL 54.390625 0 \r\nL 45.40625 0 \r\nL 45.40625 8.203125 \r\nQ 42.578125 3.328125 38.25 0.953125 \r\nQ 33.9375 -1.421875 27.875 -1.421875 \r\nQ 17.96875 -1.421875 11.734375 6.484375 \r\nQ 5.515625 14.40625 5.515625 27.296875 \r\nQ 5.515625 40.1875 11.734375 48.09375 \r\nQ 17.96875 56 27.875 56 \r\nQ 33.9375 56 38.25 53.625 \r\nQ 42.578125 51.265625 45.40625 46.390625 \r\nz\r\nM 14.796875 27.296875 \r\nQ 14.796875 17.390625 18.875 11.75 \r\nQ 22.953125 6.109375 30.078125 6.109375 \r\nQ 37.203125 6.109375 41.296875 11.75 \r\nQ 45.40625 17.390625 45.40625 27.296875 \r\nQ 45.40625 37.203125 41.296875 42.84375 \r\nQ 37.203125 48.484375 30.078125 48.484375 \r\nQ 22.953125 48.484375 18.875 42.84375 \r\nQ 14.796875 37.203125 14.796875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-100\"/>\r\n       <path d=\"M 18.3125 70.21875 \r\nL 18.3125 54.6875 \r\nL 36.8125 54.6875 \r\nL 36.8125 47.703125 \r\nL 18.3125 47.703125 \r\nL 18.3125 18.015625 \r\nQ 18.3125 11.328125 20.140625 9.421875 \r\nQ 21.96875 7.515625 27.59375 7.515625 \r\nL 36.8125 7.515625 \r\nL 36.8125 0 \r\nL 27.59375 0 \r\nQ 17.1875 0 13.234375 3.875 \r\nQ 9.28125 7.765625 9.28125 18.015625 \r\nL 9.28125 47.703125 \r\nL 2.6875 47.703125 \r\nL 2.6875 54.6875 \r\nL 9.28125 54.6875 \r\nL 9.28125 70.21875 \r\nz\r\n\" id=\"DejaVuSans-116\"/>\r\n       <path d=\"M 56.203125 29.59375 \r\nL 56.203125 25.203125 \r\nL 14.890625 25.203125 \r\nQ 15.484375 15.921875 20.484375 11.0625 \r\nQ 25.484375 6.203125 34.421875 6.203125 \r\nQ 39.59375 6.203125 44.453125 7.46875 \r\nQ 49.3125 8.734375 54.109375 11.28125 \r\nL 54.109375 2.78125 \r\nQ 49.265625 0.734375 44.1875 -0.34375 \r\nQ 39.109375 -1.421875 33.890625 -1.421875 \r\nQ 20.796875 -1.421875 13.15625 6.1875 \r\nQ 5.515625 13.8125 5.515625 26.8125 \r\nQ 5.515625 40.234375 12.765625 48.109375 \r\nQ 20.015625 56 32.328125 56 \r\nQ 43.359375 56 49.78125 48.890625 \r\nQ 56.203125 41.796875 56.203125 29.59375 \r\nz\r\nM 47.21875 32.234375 \r\nQ 47.125 39.59375 43.09375 43.984375 \r\nQ 39.0625 48.390625 32.421875 48.390625 \r\nQ 24.90625 48.390625 20.390625 44.140625 \r\nQ 15.875 39.890625 15.1875 32.171875 \r\nz\r\n\" id=\"DejaVuSans-101\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-100\"/>\r\n      <use x=\"63.476562\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"124.755859\" xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"163.964844\" xlink:href=\"#DejaVuSans-101\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_45\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"mb04ecd011b\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mb04ecd011b\" y=\"217.715214\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 112 -->\r\n      <g transform=\"translate(7.2 221.514433)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_46\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mb04ecd011b\" y=\"186.966052\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 114 -->\r\n      <g transform=\"translate(7.2 190.765271)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_47\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mb04ecd011b\" y=\"156.21689\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 116 -->\r\n      <g transform=\"translate(7.2 160.016108)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_48\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mb04ecd011b\" y=\"125.467727\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 118 -->\r\n      <g transform=\"translate(7.2 129.266946)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-56\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_49\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mb04ecd011b\" y=\"94.718565\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 120 -->\r\n      <g transform=\"translate(7.2 98.517784)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_50\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mb04ecd011b\" y=\"63.969403\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 122 -->\r\n      <g transform=\"translate(7.2 67.768622)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_51\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mb04ecd011b\" y=\"33.220241\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_15\">\r\n      <!-- 124 -->\r\n      <g transform=\"translate(7.2 37.019459)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_52\">\r\n    <path clip-path=\"url(#p79f56a95e6)\" d=\"M 33.2875 138.343062 \r\nL 35.09723 135.665054 \r\nL 36.906959 143.317241 \r\nL 38.716689 147.663754 \r\nL 40.526419 158.081033 \r\nL 42.336149 173.554607 \r\nL 44.145878 183.449688 \r\nL 45.955608 197.397543 \r\nL 47.765338 214.756364 \r\nL 49.575068 206.514905 \r\nL 53.194527 188.41338 \r\nL 55.004257 156.105512 \r\nL 56.813986 153.132129 \r\nL 58.623716 140.539685 \r\nL 60.433446 131.540179 \r\nL 64.052905 135.240968 \r\nL 65.862635 128.973647 \r\nL 69.482095 104.877723 \r\nL 71.291824 107.334499 \r\nL 73.101554 96.057299 \r\nL 74.911284 95.664693 \r\nL 76.721014 91.110245 \r\nL 78.530743 69.188158 \r\nL 80.340473 70.835514 \r\nL 82.150203 63.15537 \r\nL 83.959932 69.059297 \r\nL 85.769662 73.505378 \r\nL 87.579392 91.637487 \r\nL 91.198851 110.06551 \r\nL 93.008581 120.891007 \r\nL 94.818311 129.637257 \r\nL 96.628041 129.637257 \r\nL 98.43777 123.126636 \r\nL 100.2475 114.136526 \r\nL 102.05723 96.685725 \r\nL 103.866959 98.252952 \r\nL 105.676689 93.176481 \r\nL 107.486419 94.564357 \r\nL 109.296149 91.628197 \r\nL 111.105878 93.173381 \r\nL 112.915608 84.716524 \r\nL 114.725338 75.452398 \r\nL 116.535068 69.754638 \r\nL 118.344797 62.607902 \r\nL 120.154527 58.489385 \r\nL 121.964257 50.235262 \r\nL 123.773986 51.817172 \r\nL 125.583716 46.715689 \r\nL 127.393446 61.219992 \r\nL 132.822635 92.492864 \r\nL 134.632365 109.034282 \r\nL 136.442095 117.483964 \r\nL 138.251824 125.26541 \r\nL 140.061554 135.595403 \r\nL 141.871284 137.301966 \r\nL 143.681014 141.10605 \r\nL 145.490743 131.22442 \r\nL 147.300473 120.146663 \r\nL 149.110203 101.220451 \r\nL 150.919932 94.940306 \r\nL 152.729662 72.435638 \r\nL 154.539392 54.154752 \r\nL 156.349122 49.590939 \r\nL 158.158851 49.070324 \r\nL 159.968581 60.67485 \r\nL 161.778311 69.882943 \r\nL 163.588041 60.038966 \r\nL 165.39777 54.044548 \r\nL 167.2075 43.931347 \r\nL 169.01723 30.824998 \r\nL 170.826959 34.917543 \r\nL 172.636689 17.083636 \r\nL 174.446419 23.094375 \r\nL 176.256149 24.947517 \r\nL 178.065878 22.258485 \r\nL 179.875608 26.647901 \r\nL 181.685338 35.777025 \r\nL 183.495068 36.218585 \r\nL 185.304797 42.516228 \r\nL 187.114527 52.787889 \r\nL 188.924257 60.2802 \r\nL 190.733986 71.579573 \r\nL 192.543716 72.519289 \r\nL 194.353446 77.592126 \r\nL 196.163176 68.542097 \r\nL 197.972905 74.29692 \r\nL 199.782635 73.42371 \r\nL 203.402095 77.124927 \r\nL 205.211824 83.154174 \r\nL 207.021554 82.83814 \r\nL 208.831284 80.280086 \r\nL 210.641014 82.613559 \r\nL 212.450743 80.914494 \r\nL 214.260473 94.26623 \r\nL 217.879932 104.016752 \r\nL 219.689662 102.988294 \r\nL 221.499392 110.425802 \r\nL 223.309122 113.279511 \r\nL 225.118851 125.828439 \r\nL 226.928581 148.48399 \r\nL 228.738311 159.40809 \r\nL 230.548041 178.716562 \r\nL 232.35777 189.603362 \r\nL 234.1675 196.792215 \r\nL 235.97723 202.930351 \r\nL 237.786959 202.597272 \r\nL 239.596689 188.204 \r\nL 241.406419 175.662254 \r\nL 243.216149 151.346031 \r\nL 245.025878 146.516083 \r\nL 246.835608 144.156868 \r\nL 248.645338 144.808158 \r\nL 250.455068 148.993654 \r\nL 252.264797 147.131977 \r\nL 254.074527 139.41806 \r\nL 255.884257 123.996545 \r\nL 257.693986 124.994397 \r\nL 259.503716 130.202777 \r\nL 261.313446 144.688086 \r\nL 263.123176 152.946184 \r\nL 264.932905 155.916981 \r\nL 266.742635 136.320038 \r\nL 268.552365 122.451196 \r\nL 270.362095 91.078585 \r\nL 272.171824 64.01306 \r\nL 273.981554 44.078037 \r\nL 275.791284 36.854893 \r\nL 277.601014 32.641433 \r\nL 279.410743 28.961115 \r\nL 281.220473 36.779172 \r\nL 283.030203 30.894197 \r\nL 284.839932 57.25695 \r\nL 288.459392 81.040112 \r\nL 290.269122 91.020726 \r\nL 292.078851 97.400887 \r\nL 293.888581 102.122793 \r\nL 295.698311 102.386282 \r\nL 297.508041 105.445606 \r\nL 299.31777 103.150493 \r\nL 301.1275 103.933047 \r\nL 302.93723 106.08709 \r\nL 304.746959 108.618389 \r\nL 306.556689 104.361364 \r\nL 308.366419 109.765847 \r\nL 310.176149 102.442478 \r\nL 311.985878 106.340589 \r\nL 313.795608 110.582072 \r\nL 315.605338 123.382859 \r\nL 317.415068 137.749478 \r\nL 319.224797 144.380568 \r\nL 321.034527 157.14487 \r\nL 322.844257 154.626779 \r\nL 324.653986 168.658111 \r\nL 326.463716 170.555986 \r\nL 328.273446 177.08841 \r\nL 330.083176 186.813359 \r\nL 331.892905 180.26477 \r\nL 333.702635 179.56971 \r\nL 335.512365 176.175523 \r\nL 337.322095 165.377332 \r\nL 339.131824 162.048999 \r\nL 340.941554 150.347822 \r\nL 342.751284 133.825331 \r\nL 344.561014 143.863818 \r\nL 346.370743 143.102888 \r\nL 348.180473 151.608421 \r\nL 349.990203 156.165362 \r\nL 351.799932 148.321696 \r\nL 353.609662 143.101665 \r\nL 355.419392 154.779379 \r\nL 357.229122 148.547547 \r\nL 360.848581 138.225164 \r\nL 362.658311 124.267046 \r\nL 364.468041 124.983489 \r\nL 366.27777 123.654434 \r\nL 368.0875 123.949541 \r\nL 368.0875 123.949541 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 33.2875 224.64 \r\nL 33.2875 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 368.0875 224.64 \r\nL 368.0875 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 33.2875 224.64 \r\nL 368.0875 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 33.2875 7.2 \r\nL 368.0875 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p79f56a95e6\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"33.2875\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "us_df.plot()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='date'>"
      ]
     },
     "metadata": {},
     "execution_count": 103
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"273.394062pt\" version=\"1.1\" viewBox=\"0 0 394.375 273.394062\" width=\"394.375pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-08-08T15:57:41.226660</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 273.394062 \r\nL 394.375 273.394062 \r\nL 394.375 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 52.375 224.64 \r\nL 387.175 224.64 \r\nL 387.175 7.2 \r\nL 52.375 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"mf84f2625c6\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.375\" xlink:href=\"#mf84f2625c6\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"68.662568\" xlink:href=\"#mf84f2625c6\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- Jan -->\r\n      <g transform=\"translate(60.954755 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 9.8125 72.90625 \r\nL 19.671875 72.90625 \r\nL 19.671875 5.078125 \r\nQ 19.671875 -8.109375 14.671875 -14.0625 \r\nQ 9.671875 -20.015625 -1.421875 -20.015625 \r\nL -5.171875 -20.015625 \r\nL -5.171875 -11.71875 \r\nL -2.09375 -11.71875 \r\nQ 4.4375 -11.71875 7.125 -8.046875 \r\nQ 9.8125 -4.390625 9.8125 5.078125 \r\nz\r\n\" id=\"DejaVuSans-74\"/>\r\n        <path d=\"M 34.28125 27.484375 \r\nQ 23.390625 27.484375 19.1875 25 \r\nQ 14.984375 22.515625 14.984375 16.5 \r\nQ 14.984375 11.71875 18.140625 8.90625 \r\nQ 21.296875 6.109375 26.703125 6.109375 \r\nQ 34.1875 6.109375 38.703125 11.40625 \r\nQ 43.21875 16.703125 43.21875 25.484375 \r\nL 43.21875 27.484375 \r\nz\r\nM 52.203125 31.203125 \r\nL 52.203125 0 \r\nL 43.21875 0 \r\nL 43.21875 8.296875 \r\nQ 40.140625 3.328125 35.546875 0.953125 \r\nQ 30.953125 -1.421875 24.3125 -1.421875 \r\nQ 15.921875 -1.421875 10.953125 3.296875 \r\nQ 6 8.015625 6 15.921875 \r\nQ 6 25.140625 12.171875 29.828125 \r\nQ 18.359375 34.515625 30.609375 34.515625 \r\nL 43.21875 34.515625 \r\nL 43.21875 35.40625 \r\nQ 43.21875 41.609375 39.140625 45 \r\nQ 35.0625 48.390625 27.6875 48.390625 \r\nQ 23 48.390625 18.546875 47.265625 \r\nQ 14.109375 46.140625 10.015625 43.890625 \r\nL 10.015625 52.203125 \r\nQ 14.9375 54.109375 19.578125 55.046875 \r\nQ 24.21875 56 28.609375 56 \r\nQ 40.484375 56 46.34375 49.84375 \r\nQ 52.203125 43.703125 52.203125 31.203125 \r\nz\r\n\" id=\"DejaVuSans-97\"/>\r\n        <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-110\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-74\"/>\r\n       <use x=\"29.492188\" xlink:href=\"#DejaVuSans-97\"/>\r\n       <use x=\"90.771484\" xlink:href=\"#DejaVuSans-110\"/>\r\n      </g>\r\n      <!-- 2018 -->\r\n      <g transform=\"translate(55.937568 250.43625)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n        <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n        <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n        <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-56\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"162.768514\" xlink:href=\"#mf84f2625c6\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- Jan -->\r\n      <g transform=\"translate(155.060701 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-74\"/>\r\n       <use x=\"29.492188\" xlink:href=\"#DejaVuSans-97\"/>\r\n       <use x=\"90.771484\" xlink:href=\"#DejaVuSans-110\"/>\r\n      </g>\r\n      <!-- 2019 -->\r\n      <g transform=\"translate(150.043514 250.43625)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.984375 1.515625 \r\nL 10.984375 10.5 \r\nQ 14.703125 8.734375 18.5 7.8125 \r\nQ 22.3125 6.890625 25.984375 6.890625 \r\nQ 35.75 6.890625 40.890625 13.453125 \r\nQ 46.046875 20.015625 46.78125 33.40625 \r\nQ 43.953125 29.203125 39.59375 26.953125 \r\nQ 35.25 24.703125 29.984375 24.703125 \r\nQ 19.046875 24.703125 12.671875 31.3125 \r\nQ 6.296875 37.9375 6.296875 49.421875 \r\nQ 6.296875 60.640625 12.9375 67.421875 \r\nQ 19.578125 74.21875 30.609375 74.21875 \r\nQ 43.265625 74.21875 49.921875 64.515625 \r\nQ 56.59375 54.828125 56.59375 36.375 \r\nQ 56.59375 19.140625 48.40625 8.859375 \r\nQ 40.234375 -1.421875 26.421875 -1.421875 \r\nQ 22.703125 -1.421875 18.890625 -0.6875 \r\nQ 15.09375 0.046875 10.984375 1.515625 \r\nz\r\nM 30.609375 32.421875 \r\nQ 37.25 32.421875 41.125 36.953125 \r\nQ 45.015625 41.5 45.015625 49.421875 \r\nQ 45.015625 57.28125 41.125 61.84375 \r\nQ 37.25 66.40625 30.609375 66.40625 \r\nQ 23.96875 66.40625 20.09375 61.84375 \r\nQ 16.21875 57.28125 16.21875 49.421875 \r\nQ 16.21875 41.5 20.09375 36.953125 \r\nQ 23.96875 32.421875 30.609375 32.421875 \r\nz\r\n\" id=\"DejaVuSans-57\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-57\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"256.874459\" xlink:href=\"#mf84f2625c6\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- Jan -->\r\n      <g transform=\"translate(249.166647 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-74\"/>\r\n       <use x=\"29.492188\" xlink:href=\"#DejaVuSans-97\"/>\r\n       <use x=\"90.771484\" xlink:href=\"#DejaVuSans-110\"/>\r\n      </g>\r\n      <!-- 2020 -->\r\n      <g transform=\"translate(244.149459 250.43625)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"350.980405\" xlink:href=\"#mf84f2625c6\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- Jan -->\r\n      <g transform=\"translate(343.272593 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-74\"/>\r\n       <use x=\"29.492188\" xlink:href=\"#DejaVuSans-97\"/>\r\n       <use x=\"90.771484\" xlink:href=\"#DejaVuSans-110\"/>\r\n      </g>\r\n      <!-- 2021 -->\r\n      <g transform=\"translate(338.255405 250.43625)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-49\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"387.175\" xlink:href=\"#mf84f2625c6\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 2 \r\n\" id=\"m828d904e54\" style=\"stroke:#000000;stroke-width:0.6;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"59.613919\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_8\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"75.901486\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_9\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"83.140405\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_10\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"92.189054\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_11\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"99.427973\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_12\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"106.666892\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_13\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"115.715541\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- Jul -->\r\n      <g transform=\"translate(109.682728 237.638437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 8.5 21.578125 \r\nL 8.5 54.6875 \r\nL 17.484375 54.6875 \r\nL 17.484375 21.921875 \r\nQ 17.484375 14.15625 20.5 10.265625 \r\nQ 23.53125 6.390625 29.59375 6.390625 \r\nQ 36.859375 6.390625 41.078125 11.03125 \r\nQ 45.3125 15.671875 45.3125 23.6875 \r\nL 45.3125 54.6875 \r\nL 54.296875 54.6875 \r\nL 54.296875 0 \r\nL 45.3125 0 \r\nL 45.3125 8.40625 \r\nQ 42.046875 3.421875 37.71875 1 \r\nQ 33.40625 -1.421875 27.6875 -1.421875 \r\nQ 18.265625 -1.421875 13.375 4.4375 \r\nQ 8.5 10.296875 8.5 21.578125 \r\nz\r\nM 31.109375 56 \r\nz\r\n\" id=\"DejaVuSans-117\"/>\r\n        <path d=\"M 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\n\" id=\"DejaVuSans-108\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-74\"/>\r\n       <use x=\"29.492188\" xlink:href=\"#DejaVuSans-117\"/>\r\n       <use x=\"92.871094\" xlink:href=\"#DejaVuSans-108\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_14\">\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"122.954459\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_15\">\r\n     <g id=\"line2d_15\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"130.193378\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_16\">\r\n     <g id=\"line2d_16\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"139.242027\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_17\">\r\n     <g id=\"line2d_17\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"146.480946\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_18\">\r\n     <g id=\"line2d_18\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"153.719865\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_19\">\r\n     <g id=\"line2d_19\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"170.007432\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_20\">\r\n     <g id=\"line2d_20\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"177.246351\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_21\">\r\n     <g id=\"line2d_21\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"186.295\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_22\">\r\n     <g id=\"line2d_22\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"193.533919\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_23\">\r\n     <g id=\"line2d_23\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"200.772838\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_24\">\r\n     <g id=\"line2d_24\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"209.821486\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- Jul -->\r\n      <g transform=\"translate(203.788674 237.638437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-74\"/>\r\n       <use x=\"29.492188\" xlink:href=\"#DejaVuSans-117\"/>\r\n       <use x=\"92.871094\" xlink:href=\"#DejaVuSans-108\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_25\">\r\n     <g id=\"line2d_25\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"217.060405\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_26\">\r\n     <g id=\"line2d_26\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"226.109054\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_27\">\r\n     <g id=\"line2d_27\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"233.347973\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_28\">\r\n     <g id=\"line2d_28\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"240.586892\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_29\">\r\n     <g id=\"line2d_29\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"249.635541\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_30\">\r\n     <g id=\"line2d_30\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"264.113378\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_31\">\r\n     <g id=\"line2d_31\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"273.162027\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_32\">\r\n     <g id=\"line2d_32\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"280.400946\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_33\">\r\n     <g id=\"line2d_33\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"287.639865\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_34\">\r\n     <g id=\"line2d_34\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"296.688514\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_35\">\r\n     <g id=\"line2d_35\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"303.927432\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- Jul -->\r\n      <g transform=\"translate(297.89462 237.638437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-74\"/>\r\n       <use x=\"29.492188\" xlink:href=\"#DejaVuSans-117\"/>\r\n       <use x=\"92.871094\" xlink:href=\"#DejaVuSans-108\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_36\">\r\n     <g id=\"line2d_36\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"311.166351\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_37\">\r\n     <g id=\"line2d_37\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"320.215\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_38\">\r\n     <g id=\"line2d_38\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"327.453919\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_39\">\r\n     <g id=\"line2d_39\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"336.502568\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_40\">\r\n     <g id=\"line2d_40\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"343.741486\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_41\">\r\n     <g id=\"line2d_41\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"360.029054\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_42\">\r\n     <g id=\"line2d_42\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"367.267973\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_43\">\r\n     <g id=\"line2d_43\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"374.506892\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_44\">\r\n     <g id=\"line2d_44\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"381.745811\" xlink:href=\"#m828d904e54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_8\">\r\n     <!-- date -->\r\n     <g transform=\"translate(208.5 264.114375)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 45.40625 46.390625 \r\nL 45.40625 75.984375 \r\nL 54.390625 75.984375 \r\nL 54.390625 0 \r\nL 45.40625 0 \r\nL 45.40625 8.203125 \r\nQ 42.578125 3.328125 38.25 0.953125 \r\nQ 33.9375 -1.421875 27.875 -1.421875 \r\nQ 17.96875 -1.421875 11.734375 6.484375 \r\nQ 5.515625 14.40625 5.515625 27.296875 \r\nQ 5.515625 40.1875 11.734375 48.09375 \r\nQ 17.96875 56 27.875 56 \r\nQ 33.9375 56 38.25 53.625 \r\nQ 42.578125 51.265625 45.40625 46.390625 \r\nz\r\nM 14.796875 27.296875 \r\nQ 14.796875 17.390625 18.875 11.75 \r\nQ 22.953125 6.109375 30.078125 6.109375 \r\nQ 37.203125 6.109375 41.296875 11.75 \r\nQ 45.40625 17.390625 45.40625 27.296875 \r\nQ 45.40625 37.203125 41.296875 42.84375 \r\nQ 37.203125 48.484375 30.078125 48.484375 \r\nQ 22.953125 48.484375 18.875 42.84375 \r\nQ 14.796875 37.203125 14.796875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-100\"/>\r\n       <path d=\"M 18.3125 70.21875 \r\nL 18.3125 54.6875 \r\nL 36.8125 54.6875 \r\nL 36.8125 47.703125 \r\nL 18.3125 47.703125 \r\nL 18.3125 18.015625 \r\nQ 18.3125 11.328125 20.140625 9.421875 \r\nQ 21.96875 7.515625 27.59375 7.515625 \r\nL 36.8125 7.515625 \r\nL 36.8125 0 \r\nL 27.59375 0 \r\nQ 17.1875 0 13.234375 3.875 \r\nQ 9.28125 7.765625 9.28125 18.015625 \r\nL 9.28125 47.703125 \r\nL 2.6875 47.703125 \r\nL 2.6875 54.6875 \r\nL 9.28125 54.6875 \r\nL 9.28125 70.21875 \r\nz\r\n\" id=\"DejaVuSans-116\"/>\r\n       <path d=\"M 56.203125 29.59375 \r\nL 56.203125 25.203125 \r\nL 14.890625 25.203125 \r\nQ 15.484375 15.921875 20.484375 11.0625 \r\nQ 25.484375 6.203125 34.421875 6.203125 \r\nQ 39.59375 6.203125 44.453125 7.46875 \r\nQ 49.3125 8.734375 54.109375 11.28125 \r\nL 54.109375 2.78125 \r\nQ 49.265625 0.734375 44.1875 -0.34375 \r\nQ 39.109375 -1.421875 33.890625 -1.421875 \r\nQ 20.796875 -1.421875 13.15625 6.1875 \r\nQ 5.515625 13.8125 5.515625 26.8125 \r\nQ 5.515625 40.234375 12.765625 48.109375 \r\nQ 20.015625 56 32.328125 56 \r\nQ 43.359375 56 49.78125 48.890625 \r\nQ 56.203125 41.796875 56.203125 29.59375 \r\nz\r\nM 47.21875 32.234375 \r\nQ 47.125 39.59375 43.09375 43.984375 \r\nQ 39.0625 48.390625 32.421875 48.390625 \r\nQ 24.90625 48.390625 20.390625 44.140625 \r\nQ 15.875 39.890625 15.1875 32.171875 \r\nz\r\n\" id=\"DejaVuSans-101\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-100\"/>\r\n      <use x=\"63.476562\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"124.755859\" xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"163.964844\" xlink:href=\"#DejaVuSans-101\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_45\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m8858bbe648\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.375\" xlink:href=\"#m8858bbe648\" y=\"214.814907\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(39.0125 218.614125)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_46\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.375\" xlink:href=\"#m8858bbe648\" y=\"188.724444\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 50000 -->\r\n      <g transform=\"translate(13.5625 192.523662)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_47\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.375\" xlink:href=\"#m8858bbe648\" y=\"162.633981\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 100000 -->\r\n      <g transform=\"translate(7.2 166.433199)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_48\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.375\" xlink:href=\"#m8858bbe648\" y=\"136.543518\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 150000 -->\r\n      <g transform=\"translate(7.2 140.342736)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_49\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.375\" xlink:href=\"#m8858bbe648\" y=\"110.453055\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 200000 -->\r\n      <g transform=\"translate(7.2 114.252273)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_50\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.375\" xlink:href=\"#m8858bbe648\" y=\"84.362592\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 250000 -->\r\n      <g transform=\"translate(7.2 88.16181)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_51\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.375\" xlink:href=\"#m8858bbe648\" y=\"58.272129\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_15\">\r\n      <!-- 300000 -->\r\n      <g transform=\"translate(7.2 62.071347)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_8\">\r\n     <g id=\"line2d_52\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.375\" xlink:href=\"#m8858bbe648\" y=\"32.181666\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_16\">\r\n      <!-- 350000 -->\r\n      <g transform=\"translate(7.2 35.980884)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_53\">\r\n    <path clip-path=\"url(#p52b020691e)\" d=\"M 52.375 71.083589 \r\nL 55.994459 71.083589 \r\nL 57.804189 71.330405 \r\nL 59.613919 71.408677 \r\nL 61.423649 71.800034 \r\nL 66.852838 73.691592 \r\nL 68.662568 73.965542 \r\nL 72.282027 73.965542 \r\nL 74.091757 73.430688 \r\nL 77.711216 72.113119 \r\nL 79.520946 70.939048 \r\nL 81.330676 70.16938 \r\nL 83.140405 69.243168 \r\nL 88.569595 65.329599 \r\nL 90.379324 64.28598 \r\nL 92.189054 63.046683 \r\nL 93.998784 62.263969 \r\nL 97.618243 59.928873 \r\nL 101.237703 58.633221 \r\nL 104.857162 58.372316 \r\nL 110.286351 58.324309 \r\nL 121.14473 58.37649 \r\nL 132.003108 59.067888 \r\nL 135.622568 59.080933 \r\nL 139.242027 58.885254 \r\nL 142.861486 59.133114 \r\nL 144.671216 59.354883 \r\nL 150.100405 60.515908 \r\nL 153.719865 61.676934 \r\nL 155.529595 62.074553 \r\nL 157.339324 62.726814 \r\nL 159.149054 63.118171 \r\nL 160.958784 63.261669 \r\nL 162.768514 63.581538 \r\nL 168.197703 63.581538 \r\nL 171.817162 62.211788 \r\nL 175.436622 59.863647 \r\nL 180.865811 57.909993 \r\nL 184.48527 55.300947 \r\nL 186.295 53.657247 \r\nL 188.10473 52.219141 \r\nL 189.914459 51.436427 \r\nL 191.724189 50.249311 \r\nL 193.533919 49.283964 \r\nL 195.343649 48.631702 \r\nL 197.153378 47.601129 \r\nL 200.772838 46.179199 \r\nL 202.582568 45.539983 \r\nL 204.392297 45.279078 \r\nL 206.202027 45.396485 \r\nL 208.011757 45.750272 \r\nL 213.440946 47.563559 \r\nL 215.250676 47.862034 \r\nL 217.060405 47.992486 \r\nL 218.870135 48.310268 \r\nL 224.299324 50.123555 \r\nL 226.109054 50.725723 \r\nL 227.918784 51.051854 \r\nL 229.728514 51.573141 \r\nL 231.538243 52.212358 \r\nL 235.157703 52.936629 \r\nL 240.586892 53.411997 \r\nL 244.206351 54.755656 \r\nL 246.016081 55.994953 \r\nL 247.825811 57.039093 \r\nL 251.44527 58.304481 \r\nL 255.06473 58.481896 \r\nL 260.493919 58.793938 \r\nL 265.923108 58.429715 \r\nL 267.732838 58.181856 \r\nL 269.542568 57.255644 \r\nL 271.352297 55.951121 \r\nL 274.971757 52.206096 \r\nL 276.781486 50.77112 \r\nL 278.591216 50.105814 \r\nL 282.210676 50.053633 \r\nL 284.020405 50.327583 \r\nL 285.830135 49.805773 \r\nL 287.639865 49.153512 \r\nL 294.878784 44.078917 \r\nL 302.117703 39.252181 \r\nL 303.927432 38.482512 \r\nL 305.737162 37.843296 \r\nL 307.546892 37.556301 \r\nL 309.356622 37.425849 \r\nL 312.976081 37.399758 \r\nL 314.785811 37.269306 \r\nL 316.595541 37.008401 \r\nL 320.215 36.238733 \r\nL 322.02473 35.990873 \r\nL 323.834459 35.612561 \r\nL 329.263649 34.842893 \r\nL 331.073378 34.9603 \r\nL 332.883108 35.221204 \r\nL 334.692838 35.707531 \r\nL 338.312297 36.894647 \r\nL 341.931757 37.910088 \r\nL 345.551216 39.18852 \r\nL 349.170676 41.099908 \r\nL 352.790135 42.443566 \r\nL 354.599865 42.709689 \r\nL 356.409595 42.709689 \r\nL 358.219324 42.567235 \r\nL 360.029054 41.888883 \r\nL 363.648514 39.357586 \r\nL 367.267973 35.638652 \r\nL 370.887432 32.725391 \r\nL 374.506892 29.150997 \r\nL 379.936081 22.308512 \r\nL 383.555541 19.266886 \r\nL 385.36527 17.975408 \r\nL 387.175 17.083636 \r\nL 387.175 17.083636 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_54\">\r\n    <path clip-path=\"url(#p52b020691e)\" d=\"M 52.375 92.138071 \r\nL 54.18473 92.320183 \r\nL 55.994459 91.798374 \r\nL 57.804189 91.711753 \r\nL 61.423649 90.315913 \r\nL 63.233378 90.185461 \r\nL 65.043108 89.763317 \r\nL 66.852838 89.028088 \r\nL 68.662568 89.869245 \r\nL 72.282027 91.160723 \r\nL 74.091757 92.93957 \r\nL 75.901486 92.581087 \r\nL 77.711216 92.868083 \r\nL 79.520946 92.476726 \r\nL 81.330676 91.694012 \r\nL 83.140405 90.780845 \r\nL 84.950135 90.102493 \r\nL 88.569595 89.554072 \r\nL 90.379324 88.510453 \r\nL 92.189054 88.249549 \r\nL 95.808514 86.971638 \r\nL 97.618243 87.504927 \r\nL 99.427973 86.852665 \r\nL 101.237703 86.852665 \r\nL 103.047432 86.330856 \r\nL 104.857162 85.928019 \r\nL 106.666892 84.623496 \r\nL 110.286351 83.31219 \r\nL 112.096081 82.529476 \r\nL 113.905811 81.890259 \r\nL 115.715541 81.890259 \r\nL 117.52527 82.366671 \r\nL 119.335 83.018933 \r\nL 121.14473 84.310411 \r\nL 122.954459 84.297365 \r\nL 124.764189 84.753949 \r\nL 126.573919 84.753949 \r\nL 128.383649 85.014853 \r\nL 130.193378 85.014853 \r\nL 133.812838 86.377819 \r\nL 137.432297 87.160533 \r\nL 139.242027 87.37604 \r\nL 141.051757 88.028302 \r\nL 142.861486 88.028302 \r\nL 144.671216 88.550111 \r\nL 146.480946 87.884804 \r\nL 150.100405 87.10209 \r\nL 151.910135 86.854231 \r\nL 153.719865 86.201969 \r\nL 155.529595 85.941065 \r\nL 157.339324 85.941065 \r\nL 159.149054 85.536662 \r\nL 162.768514 85.536662 \r\nL 166.387973 87.036864 \r\nL 168.197703 88.341387 \r\nL 170.007432 88.184844 \r\nL 171.817162 89.163237 \r\nL 173.626892 89.424141 \r\nL 175.436622 88.77188 \r\nL 177.246351 88.276161 \r\nL 180.865811 85.797567 \r\nL 182.675541 85.40621 \r\nL 186.295 84.114732 \r\nL 188.10473 83.853828 \r\nL 189.914459 82.940661 \r\nL 191.724189 83.214611 \r\nL 193.533919 82.027495 \r\nL 197.153378 80.736017 \r\nL 198.963108 79.809806 \r\nL 200.772838 78.635735 \r\nL 202.582568 78.087835 \r\nL 206.202027 76.770267 \r\nL 209.821486 76.198886 \r\nL 211.631216 76.655469 \r\nL 213.440946 76.720695 \r\nL 215.250676 77.633861 \r\nL 217.060405 77.318167 \r\nL 220.679865 78.035654 \r\nL 222.489595 78.427011 \r\nL 224.299324 78.427011 \r\nL 227.918784 79.405404 \r\nL 229.728514 79.66683 \r\nL 231.538243 80.319092 \r\nL 233.347973 79.66683 \r\nL 235.157703 79.601604 \r\nL 236.967432 79.353223 \r\nL 238.777162 79.483675 \r\nL 240.586892 79.157544 \r\nL 242.396622 79.483675 \r\nL 244.206351 79.144499 \r\nL 246.016081 78.492237 \r\nL 247.825811 78.557464 \r\nL 249.635541 77.644297 \r\nL 251.44527 77.318167 \r\nL 253.255 76.798445 \r\nL 255.06473 76.420133 \r\nL 256.874459 76.550585 \r\nL 258.684189 77.789882 \r\nL 260.493919 78.831413 \r\nL 262.303649 80.579474 \r\nL 264.113378 80.840379 \r\nL 265.923108 80.905605 \r\nL 267.732838 80.644701 \r\nL 269.542568 79.535856 \r\nL 273.162027 77.513845 \r\nL 274.971757 77.122488 \r\nL 276.781486 75.83101 \r\nL 278.591216 74.865663 \r\nL 280.400946 73.691592 \r\nL 282.210676 73.039331 \r\nL 284.020405 73.039331 \r\nL 285.830135 74.13513 \r\nL 287.639865 74.656939 \r\nL 289.449595 75.961462 \r\nL 291.259324 76.992036 \r\nL 293.069054 77.383393 \r\nL 294.878784 76.861583 \r\nL 296.688514 76.209322 \r\nL 298.498243 75.426608 \r\nL 300.307973 73.926406 \r\nL 302.117703 73.404597 \r\nL 303.927432 70.795551 \r\nL 305.737162 69.360575 \r\nL 307.546892 68.186504 \r\nL 309.356622 67.286384 \r\nL 311.166351 66.764574 \r\nL 312.976081 66.373217 \r\nL 314.785811 66.242765 \r\nL 316.595541 65.776268 \r\nL 318.40527 65.645815 \r\nL 322.02473 64.870928 \r\nL 323.834459 64.345988 \r\nL 325.644189 64.476441 \r\nL 327.453919 63.824179 \r\nL 329.263649 64.207709 \r\nL 332.883108 63.855488 \r\nL 336.502568 62.550964 \r\nL 338.312297 62.446603 \r\nL 340.122027 61.794341 \r\nL 341.931757 62.446603 \r\nL 343.741486 61.794341 \r\nL 345.551216 62.185698 \r\nL 347.360946 62.446603 \r\nL 349.170676 62.446603 \r\nL 350.980405 63.595105 \r\nL 352.790135 64.247366 \r\nL 354.599865 64.769176 \r\nL 356.409595 65.682342 \r\nL 358.219324 65.838363 \r\nL 361.838784 66.555851 \r\nL 363.648514 64.599066 \r\nL 365.458243 63.098864 \r\nL 367.267973 60.750723 \r\nL 369.077703 59.120069 \r\nL 370.887432 58.533033 \r\nL 372.697162 57.424188 \r\nL 374.506892 54.888717 \r\nL 376.316622 53.453742 \r\nL 378.126351 51.823088 \r\nL 379.936081 50.518565 \r\nL 381.745811 50.44499 \r\nL 383.555541 49.140466 \r\nL 385.36527 48.168336 \r\nL 387.175 47.386144 \r\nL 387.175 47.386144 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_55\">\r\n    <path clip-path=\"url(#p52b020691e)\" d=\"M 52.375 214.75377 \r\nL 387.175 214.753282 \r\nL 387.175 214.753282 \r\n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_56\">\r\n    <path clip-path=\"url(#p52b020691e)\" d=\"M 52.375 193.760425 \r\nL 54.18473 193.578313 \r\nL 55.994459 194.100123 \r\nL 57.804189 194.433559 \r\nL 59.613919 195.164092 \r\nL 61.423649 196.299027 \r\nL 63.233378 197.081741 \r\nL 65.043108 198.156146 \r\nL 66.852838 199.478411 \r\nL 70.472297 198.271988 \r\nL 72.282027 197.619726 \r\nL 74.091757 195.306024 \r\nL 75.901486 195.012245 \r\nL 77.711216 194.059943 \r\nL 79.520946 193.277229 \r\nL 83.140405 193.277229 \r\nL 84.950135 192.651058 \r\nL 88.569595 190.590434 \r\nL 90.379324 190.590434 \r\nL 92.189054 189.612041 \r\nL 93.998784 189.454977 \r\nL 95.808514 188.946213 \r\nL 97.618243 187.238853 \r\nL 99.427973 187.234678 \r\nL 101.237703 186.595462 \r\nL 104.857162 187.259203 \r\nL 106.666892 188.51572 \r\nL 110.286351 189.827027 \r\nL 112.096081 190.609741 \r\nL 113.905811 191.248957 \r\nL 115.715541 191.248957 \r\nL 117.52527 190.772545 \r\nL 119.335 190.120283 \r\nL 121.14473 188.880986 \r\nL 122.954459 189.011439 \r\nL 124.764189 188.672263 \r\nL 126.573919 188.78967 \r\nL 128.383649 188.593991 \r\nL 130.193378 188.724444 \r\nL 135.622568 187.126664 \r\nL 137.432297 186.6179 \r\nL 139.242027 186.324121 \r\nL 141.051757 185.789267 \r\nL 142.861486 185.919719 \r\nL 144.671216 185.619679 \r\nL 146.480946 186.663297 \r\nL 151.910135 189.037529 \r\nL 153.719865 190.289871 \r\nL 157.339324 191.600656 \r\nL 159.149054 192.396415 \r\nL 160.958784 192.539913 \r\nL 162.768514 192.859782 \r\nL 166.387973 191.372626 \r\nL 168.197703 190.055057 \r\nL 170.007432 189.507158 \r\nL 171.817162 187.863458 \r\nL 173.626892 186.428483 \r\nL 175.436622 185.906674 \r\nL 177.246351 185.750131 \r\nL 179.056081 186.415438 \r\nL 180.865811 186.927333 \r\nL 182.675541 186.014166 \r\nL 184.48527 185.361905 \r\nL 186.295 184.357422 \r\nL 188.10473 183.18022 \r\nL 189.914459 183.310673 \r\nL 191.724189 181.849607 \r\nL 193.533919 182.071376 \r\nL 195.343649 182.071376 \r\nL 197.153378 181.680019 \r\nL 198.963108 181.836561 \r\nL 200.772838 182.358371 \r\nL 202.582568 182.267054 \r\nL 204.392297 182.671456 \r\nL 206.202027 183.441125 \r\nL 208.011757 184.055816 \r\nL 209.821486 185.005509 \r\nL 211.631216 185.188142 \r\nL 213.440946 185.657771 \r\nL 215.250676 185.043079 \r\nL 217.060405 185.489226 \r\nL 218.870135 185.480877 \r\nL 222.489595 185.976596 \r\nL 224.299324 186.511451 \r\nL 226.109054 186.591809 \r\nL 227.918784 186.461357 \r\nL 229.728514 186.721218 \r\nL 231.538243 186.708173 \r\nL 233.347973 187.745529 \r\nL 236.967432 188.54181 \r\nL 238.777162 188.476584 \r\nL 240.586892 189.06936 \r\nL 242.396622 189.382445 \r\nL 244.206351 190.426064 \r\nL 246.016081 192.317622 \r\nL 247.825811 193.296536 \r\nL 249.635541 194.875009 \r\nL 251.44527 195.801221 \r\nL 255.06473 196.87667 \r\nL 256.874459 196.863625 \r\nL 258.684189 195.741735 \r\nL 260.493919 194.777431 \r\nL 262.303649 192.911963 \r\nL 264.113378 192.533651 \r\nL 265.923108 192.339016 \r\nL 267.732838 192.352062 \r\nL 269.542568 192.534695 \r\nL 271.352297 192.208564 \r\nL 273.162027 191.346535 \r\nL 274.971757 189.898515 \r\nL 276.781486 189.755017 \r\nL 278.591216 190.055057 \r\nL 280.400946 191.176947 \r\nL 282.210676 191.829209 \r\nL 284.020405 192.103159 \r\nL 285.830135 190.48555 \r\nL 287.639865 189.311479 \r\nL 289.449595 186.715478 \r\nL 291.259324 184.497789 \r\nL 293.069054 182.801909 \r\nL 294.878784 182.03224 \r\nL 298.498243 180.975576 \r\nL 300.307973 181.327797 \r\nL 302.117703 180.662491 \r\nL 303.927432 182.501868 \r\nL 309.356622 184.954372 \r\nL 311.166351 185.463136 \r\nL 312.976081 185.841448 \r\nL 314.785811 185.841448 \r\nL 316.595541 186.04704 \r\nL 318.40527 185.799181 \r\nL 320.215 185.799181 \r\nL 323.834459 186.08148 \r\nL 325.644189 185.690123 \r\nL 327.453919 186.094525 \r\nL 329.263649 185.450091 \r\nL 332.883108 186.180624 \r\nL 334.692838 187.319211 \r\nL 336.502568 188.623734 \r\nL 338.312297 189.262951 \r\nL 340.122027 190.423976 \r\nL 341.931757 190.278392 \r\nL 343.741486 191.56987 \r\nL 345.551216 191.817729 \r\nL 347.360946 192.50443 \r\nL 349.170676 193.468212 \r\nL 350.980405 192.985016 \r\nL 352.790135 193.011107 \r\nL 354.599865 192.75542 \r\nL 356.409595 191.842254 \r\nL 358.219324 191.543779 \r\nL 360.029054 190.47407 \r\nL 361.838784 188.934211 \r\nL 363.648514 189.573427 \r\nL 365.458243 189.246253 \r\nL 367.267973 189.702836 \r\nL 369.077703 189.898515 \r\nL 370.887432 189.007264 \r\nL 372.697162 188.289777 \r\nL 374.506892 189.077187 \r\nL 378.126351 187.387047 \r\nL 379.936081 186.604854 \r\nL 381.745811 185.099957 \r\nL 383.555541 184.941327 \r\nL 385.36527 184.621979 \r\nL 387.175 184.512399 \r\nL 387.175 184.512399 \r\n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 52.375 224.64 \r\nL 52.375 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 387.175 224.64 \r\nL 387.175 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 52.375 224.64 \r\nL 387.175 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 52.375 7.2 \r\nL 387.175 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"legend_1\">\r\n    <g id=\"patch_7\">\r\n     <path d=\"M 249.03125 146.77625 \r\nL 380.175 146.77625 \r\nQ 382.175 146.77625 382.175 144.77625 \r\nL 382.175 87.06375 \r\nQ 382.175 85.06375 380.175 85.06375 \r\nL 249.03125 85.06375 \r\nQ 247.03125 85.06375 247.03125 87.06375 \r\nL 247.03125 144.77625 \r\nQ 247.03125 146.77625 249.03125 146.77625 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_57\">\r\n     <path d=\"M 251.03125 93.162187 \r\nL 271.03125 93.162187 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_58\"/>\r\n    <g id=\"text_17\">\r\n     <!-- list price -->\r\n     <g transform=\"translate(279.03125 96.662187)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 9.421875 54.6875 \r\nL 18.40625 54.6875 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\nM 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 64.59375 \r\nL 9.421875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-105\"/>\r\n       <path d=\"M 44.28125 53.078125 \r\nL 44.28125 44.578125 \r\nQ 40.484375 46.53125 36.375 47.5 \r\nQ 32.28125 48.484375 27.875 48.484375 \r\nQ 21.1875 48.484375 17.84375 46.4375 \r\nQ 14.5 44.390625 14.5 40.28125 \r\nQ 14.5 37.15625 16.890625 35.375 \r\nQ 19.28125 33.59375 26.515625 31.984375 \r\nL 29.59375 31.296875 \r\nQ 39.15625 29.25 43.1875 25.515625 \r\nQ 47.21875 21.78125 47.21875 15.09375 \r\nQ 47.21875 7.46875 41.1875 3.015625 \r\nQ 35.15625 -1.421875 24.609375 -1.421875 \r\nQ 20.21875 -1.421875 15.453125 -0.5625 \r\nQ 10.6875 0.296875 5.421875 2 \r\nL 5.421875 11.28125 \r\nQ 10.40625 8.6875 15.234375 7.390625 \r\nQ 20.0625 6.109375 24.8125 6.109375 \r\nQ 31.15625 6.109375 34.5625 8.28125 \r\nQ 37.984375 10.453125 37.984375 14.40625 \r\nQ 37.984375 18.0625 35.515625 20.015625 \r\nQ 33.0625 21.96875 24.703125 23.78125 \r\nL 21.578125 24.515625 \r\nQ 13.234375 26.265625 9.515625 29.90625 \r\nQ 5.8125 33.546875 5.8125 39.890625 \r\nQ 5.8125 47.609375 11.28125 51.796875 \r\nQ 16.75 56 26.8125 56 \r\nQ 31.78125 56 36.171875 55.265625 \r\nQ 40.578125 54.546875 44.28125 53.078125 \r\nz\r\n\" id=\"DejaVuSans-115\"/>\r\n       <path id=\"DejaVuSans-32\"/>\r\n       <path d=\"M 18.109375 8.203125 \r\nL 18.109375 -20.796875 \r\nL 9.078125 -20.796875 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.390625 \r\nQ 20.953125 51.265625 25.265625 53.625 \r\nQ 29.59375 56 35.59375 56 \r\nQ 45.5625 56 51.78125 48.09375 \r\nQ 58.015625 40.1875 58.015625 27.296875 \r\nQ 58.015625 14.40625 51.78125 6.484375 \r\nQ 45.5625 -1.421875 35.59375 -1.421875 \r\nQ 29.59375 -1.421875 25.265625 0.953125 \r\nQ 20.953125 3.328125 18.109375 8.203125 \r\nz\r\nM 48.6875 27.296875 \r\nQ 48.6875 37.203125 44.609375 42.84375 \r\nQ 40.53125 48.484375 33.40625 48.484375 \r\nQ 26.265625 48.484375 22.1875 42.84375 \r\nQ 18.109375 37.203125 18.109375 27.296875 \r\nQ 18.109375 17.390625 22.1875 11.75 \r\nQ 26.265625 6.109375 33.40625 6.109375 \r\nQ 40.53125 6.109375 44.609375 11.75 \r\nQ 48.6875 17.390625 48.6875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-112\"/>\r\n       <path d=\"M 41.109375 46.296875 \r\nQ 39.59375 47.171875 37.8125 47.578125 \r\nQ 36.03125 48 33.890625 48 \r\nQ 26.265625 48 22.1875 43.046875 \r\nQ 18.109375 38.09375 18.109375 28.8125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 20.953125 51.171875 25.484375 53.578125 \r\nQ 30.03125 56 36.53125 56 \r\nQ 37.453125 56 38.578125 55.875 \r\nQ 39.703125 55.765625 41.0625 55.515625 \r\nz\r\n\" id=\"DejaVuSans-114\"/>\r\n       <path d=\"M 48.78125 52.59375 \r\nL 48.78125 44.1875 \r\nQ 44.96875 46.296875 41.140625 47.34375 \r\nQ 37.3125 48.390625 33.40625 48.390625 \r\nQ 24.65625 48.390625 19.8125 42.84375 \r\nQ 14.984375 37.3125 14.984375 27.296875 \r\nQ 14.984375 17.28125 19.8125 11.734375 \r\nQ 24.65625 6.203125 33.40625 6.203125 \r\nQ 37.3125 6.203125 41.140625 7.25 \r\nQ 44.96875 8.296875 48.78125 10.40625 \r\nL 48.78125 2.09375 \r\nQ 45.015625 0.34375 40.984375 -0.53125 \r\nQ 36.96875 -1.421875 32.421875 -1.421875 \r\nQ 20.0625 -1.421875 12.78125 6.34375 \r\nQ 5.515625 14.109375 5.515625 27.296875 \r\nQ 5.515625 40.671875 12.859375 48.328125 \r\nQ 20.21875 56 33.015625 56 \r\nQ 37.15625 56 41.109375 55.140625 \r\nQ 45.0625 54.296875 48.78125 52.59375 \r\nz\r\n\" id=\"DejaVuSans-99\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"27.783203\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"55.566406\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"107.666016\" xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"146.875\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"178.662109\" xlink:href=\"#DejaVuSans-112\"/>\r\n      <use x=\"242.138672\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"283.251953\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"311.035156\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"366.015625\" xlink:href=\"#DejaVuSans-101\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_59\">\r\n     <path d=\"M 251.03125 107.840312 \r\nL 271.03125 107.840312 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_60\"/>\r\n    <g id=\"text_18\">\r\n     <!-- sale price -->\r\n     <g transform=\"translate(279.03125 111.340312)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"52.099609\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"113.378906\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"141.162109\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"202.685547\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"234.472656\" xlink:href=\"#DejaVuSans-112\"/>\r\n      <use x=\"297.949219\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"339.0625\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"366.845703\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"421.826172\" xlink:href=\"#DejaVuSans-101\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_61\">\r\n     <path d=\"M 251.03125 122.518437 \r\nL 271.03125 122.518437 \r\n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_62\"/>\r\n    <g id=\"text_19\">\r\n     <!-- list/sale percent diff -->\r\n     <g transform=\"translate(279.03125 126.018437)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 25.390625 72.90625 \r\nL 33.6875 72.90625 \r\nL 8.296875 -9.28125 \r\nL 0 -9.28125 \r\nz\r\n\" id=\"DejaVuSans-47\"/>\r\n       <path d=\"M 37.109375 75.984375 \r\nL 37.109375 68.5 \r\nL 28.515625 68.5 \r\nQ 23.6875 68.5 21.796875 66.546875 \r\nQ 19.921875 64.59375 19.921875 59.515625 \r\nL 19.921875 54.6875 \r\nL 34.71875 54.6875 \r\nL 34.71875 47.703125 \r\nL 19.921875 47.703125 \r\nL 19.921875 0 \r\nL 10.890625 0 \r\nL 10.890625 47.703125 \r\nL 2.296875 47.703125 \r\nL 2.296875 54.6875 \r\nL 10.890625 54.6875 \r\nL 10.890625 58.5 \r\nQ 10.890625 67.625 15.140625 71.796875 \r\nQ 19.390625 75.984375 28.609375 75.984375 \r\nz\r\n\" id=\"DejaVuSans-102\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"27.783203\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"55.566406\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"107.666016\" xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"146.875\" xlink:href=\"#DejaVuSans-47\"/>\r\n      <use x=\"180.566406\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"232.666016\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"293.945312\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"321.728516\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"383.251953\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"415.039062\" xlink:href=\"#DejaVuSans-112\"/>\r\n      <use x=\"478.515625\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"540.039062\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"578.902344\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"633.882812\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"695.40625\" xlink:href=\"#DejaVuSans-110\"/>\r\n      <use x=\"758.785156\" xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"797.994141\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"829.78125\" xlink:href=\"#DejaVuSans-100\"/>\r\n      <use x=\"893.257812\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"921.041016\" xlink:href=\"#DejaVuSans-102\"/>\r\n      <use x=\"956.246094\" xlink:href=\"#DejaVuSans-102\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_63\">\r\n     <path d=\"M 251.03125 137.196562 \r\nL 271.03125 137.196562 \r\n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_64\"/>\r\n    <g id=\"text_20\">\r\n     <!-- list/sale actual diff -->\r\n     <g transform=\"translate(279.03125 140.696562)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"27.783203\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"55.566406\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"107.666016\" xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"146.875\" xlink:href=\"#DejaVuSans-47\"/>\r\n      <use x=\"180.566406\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"232.666016\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"293.945312\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"321.728516\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"383.251953\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"415.039062\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"476.318359\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"531.298828\" xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"570.507812\" xlink:href=\"#DejaVuSans-117\"/>\r\n      <use x=\"633.886719\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"695.166016\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"722.949219\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"754.736328\" xlink:href=\"#DejaVuSans-100\"/>\r\n      <use x=\"818.212891\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"845.996094\" xlink:href=\"#DejaVuSans-102\"/>\r\n      <use x=\"881.201172\" xlink:href=\"#DejaVuSans-102\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p52b020691e\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"52.375\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "# https://towardsdatascience.com/time-series-modeling-using-scikit-pandas-and-numpy-682e3b8db8d1 \r\n",
    "import sklearn.metrics as metrics\r\n",
    "\r\n",
    "def regression_results(y_true, y_pred):\r\n",
    "    # Regression metrics\r\n",
    "    explained_variance=metrics.explained_variance_score(y_true, y_pred)\r\n",
    "    mean_absolute_error=metrics.mean_absolute_error(y_true, y_pred) \r\n",
    "    mse=metrics.mean_squared_error(y_true, y_pred) \r\n",
    "    mean_squared_log_error=metrics.mean_squared_log_error(y_true, y_pred)\r\n",
    "    median_absolute_error=metrics.median_absolute_error(y_true, y_pred)\r\n",
    "    r2=metrics.r2_score(y_true, y_pred)\r\n",
    "    print('explained_variance: ', round(explained_variance,4))    \r\n",
    "    print('mean_squared_log_error: ', round(mean_squared_log_error,4))\r\n",
    "    print('r2: ', round(r2,4))\r\n",
    "    print('MAE: ', round(mean_absolute_error,4))\r\n",
    "    print('MSE: ', round(mse,4))\r\n",
    "    print('RMSE: ', round(np.sqrt(mse),4))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "X_train = us_df.drop(['sale price'], axis = 1)\r\n",
    "y_train = us_df.loc[:\"2018\", 'sale price']\r\n",
    "X_test = us_df.drop(['sale price'], axis = 1)\r\n",
    "y_test = us_df.loc['sale price']"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'sale price'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mpandas\\_libs\\tslibs\\conversion.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.conversion._convert_str_to_tsobject\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\tslibs\\parsing.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\mlenv\\lib\\site-packages\\dateutil\\parser\\_parser.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(timestr, parserinfo, **kwargs)\u001b[0m\n\u001b[0;32m   1373\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mDEFAULTPARSER\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\mlenv\\lib\\site-packages\\dateutil\\parser\\_parser.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[0;32m    648\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mParserError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown string format: %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimestr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Unknown string format: sale price",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mD:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\indexes\\datetimes.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    663\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 664\u001b[1;33m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_for_get_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    665\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\indexes\\datetimes.py\u001b[0m in \u001b[0;36m_maybe_cast_for_get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[1;31m# needed to localize naive datetimes or dates (GH 35690)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 692\u001b[1;33m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTimestamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    693\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtzinfo\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\tslibs\\timestamps.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.timestamps.Timestamp.__new__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\tslibs\\conversion.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.conversion.convert_to_tsobject\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\tslibs\\conversion.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.conversion._convert_str_to_tsobject\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to Timestamp",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-105-00d428b0e916>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mus_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sale price'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mus_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sale price'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mus_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sale price'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mus_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sale price'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;31m# fall thru to straight lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1071\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1072\u001b[0m         \u001b[1;31m# GH#5667 this will fail if the label is not present in the axis.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1073\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_lowerdim_multi_index_axis0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mxs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   3737\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Expected label or tuple of labels, got {key}\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3739\u001b[1;33m             \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3740\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3741\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\indexes\\datetimes.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    664\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_for_get_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 666\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    667\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'sale price'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "models = []\r\n",
    "models.append(('LR', LinearRegression()))\r\n",
    "models.append(('NN',  MLPRegressor(solver = 'lbfgs')))  #neural network\r\n",
    "models.append(('KNN', KNeighborsRegressor())) \r\n",
    "models.append(('RF', RandomForestRegressor(n_estimators = 10))) # Ensemble method - collection of many decision trees\r\n",
    "models.append(('SVR', SVR(gamma='auto'))) # kernel = linear\r\n",
    "# Evaluate each model in turn\r\n",
    "results = []\r\n",
    "names = []\r\n",
    "for name, model in models:\r\n",
    "    # TimeSeries Cross validation\r\n",
    " tscv = TimeSeriesSplit(n_splits=8)\r\n",
    "    \r\n",
    " cv_results = cross_val_score(model, X_train, y_train, cv=tscv, scoring='r2')\r\n",
    " results.append(cv_results)\r\n",
    " names.append(name)\r\n",
    " print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))\r\n",
    "    \r\n",
    "# Compare Algorithms\r\n",
    "plt.boxplot(results, labels=names)\r\n",
    "plt.title('Algorithm Comparison')\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 518, in fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 518, in fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 518, in fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 518, in fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 518, in fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 518, in fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 518, in fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 518, in fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 364, in _fit\n",
      "    X, y = self._validate_input(X, y, incremental, reset=first_pass)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 1414, in _validate_input\n",
      "    X, y = self._validate_data(X, y, accept_sparse=['csr', 'csc'],\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 364, in _fit\n",
      "    X, y = self._validate_input(X, y, incremental, reset=first_pass)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 1414, in _validate_input\n",
      "    X, y = self._validate_data(X, y, accept_sparse=['csr', 'csc'],\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 364, in _fit\n",
      "    X, y = self._validate_input(X, y, incremental, reset=first_pass)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 1414, in _validate_input\n",
      "    X, y = self._validate_data(X, y, accept_sparse=['csr', 'csc'],\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 364, in _fit\n",
      "    X, y = self._validate_input(X, y, incremental, reset=first_pass)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 1414, in _validate_input\n",
      "    X, y = self._validate_data(X, y, accept_sparse=['csr', 'csc'],\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LR: nan (nan)\n",
      "NN: nan (nan)\n",
      "KNN: nan (nan)\n",
      "RF: nan (nan)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 364, in _fit\n",
      "    X, y = self._validate_input(X, y, incremental, reset=first_pass)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 1414, in _validate_input\n",
      "    X, y = self._validate_data(X, y, accept_sparse=['csr', 'csc'],\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 364, in _fit\n",
      "    X, y = self._validate_input(X, y, incremental, reset=first_pass)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 1414, in _validate_input\n",
      "    X, y = self._validate_data(X, y, accept_sparse=['csr', 'csc'],\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 364, in _fit\n",
      "    X, y = self._validate_input(X, y, incremental, reset=first_pass)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 1414, in _validate_input\n",
      "    X, y = self._validate_data(X, y, accept_sparse=['csr', 'csc'],\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 364, in _fit\n",
      "    X, y = self._validate_input(X, y, incremental, reset=first_pass)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 1414, in _validate_input\n",
      "    X, y = self._validate_data(X, y, accept_sparse=['csr', 'csc'],\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neighbors\\_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neighbors\\_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neighbors\\_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neighbors\\_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neighbors\\_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neighbors\\_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neighbors\\_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neighbors\\_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 169, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 169, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 169, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 169, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 169, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 169, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 169, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 169, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"D:\\anaconda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'United States'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SVR: nan (nan)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"263.63625pt\" version=\"1.1\" viewBox=\"0 0 386.845312 263.63625\" width=\"386.845312pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-08-08T15:27:37.846447</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 263.63625 \r\nL 386.845312 263.63625 \r\nL 386.845312 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 44.845313 239.758125 \r\nL 379.645313 239.758125 \r\nL 379.645313 22.318125 \r\nL 44.845313 22.318125 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m3bb40d583f\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"78.325313\" xlink:href=\"#m3bb40d583f\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- LR -->\r\n      <g transform=\"translate(72.065156 254.356563)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 9.8125 72.90625 \r\nL 19.671875 72.90625 \r\nL 19.671875 8.296875 \r\nL 55.171875 8.296875 \r\nL 55.171875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-76\"/>\r\n        <path d=\"M 44.390625 34.1875 \r\nQ 47.5625 33.109375 50.5625 29.59375 \r\nQ 53.5625 26.078125 56.59375 19.921875 \r\nL 66.609375 0 \r\nL 56 0 \r\nL 46.6875 18.703125 \r\nQ 43.0625 26.03125 39.671875 28.421875 \r\nQ 36.28125 30.8125 30.421875 30.8125 \r\nL 19.671875 30.8125 \r\nL 19.671875 0 \r\nL 9.8125 0 \r\nL 9.8125 72.90625 \r\nL 32.078125 72.90625 \r\nQ 44.578125 72.90625 50.734375 67.671875 \r\nQ 56.890625 62.453125 56.890625 51.90625 \r\nQ 56.890625 45.015625 53.6875 40.46875 \r\nQ 50.484375 35.9375 44.390625 34.1875 \r\nz\r\nM 19.671875 64.796875 \r\nL 19.671875 38.921875 \r\nL 32.078125 38.921875 \r\nQ 39.203125 38.921875 42.84375 42.21875 \r\nQ 46.484375 45.515625 46.484375 51.90625 \r\nQ 46.484375 58.296875 42.84375 61.546875 \r\nQ 39.203125 64.796875 32.078125 64.796875 \r\nz\r\n\" id=\"DejaVuSans-82\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-76\"/>\r\n       <use x=\"55.712891\" xlink:href=\"#DejaVuSans-82\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"145.285313\" xlink:href=\"#m3bb40d583f\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- NN -->\r\n      <g transform=\"translate(137.804063 254.356563)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 9.8125 72.90625 \r\nL 23.09375 72.90625 \r\nL 55.421875 11.921875 \r\nL 55.421875 72.90625 \r\nL 64.984375 72.90625 \r\nL 64.984375 0 \r\nL 51.703125 0 \r\nL 19.390625 60.984375 \r\nL 19.390625 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-78\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-78\"/>\r\n       <use x=\"74.804688\" xlink:href=\"#DejaVuSans-78\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"212.245313\" xlink:href=\"#m3bb40d583f\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- KNN -->\r\n      <g transform=\"translate(201.485156 254.356563)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 9.8125 72.90625 \r\nL 19.671875 72.90625 \r\nL 19.671875 42.09375 \r\nL 52.390625 72.90625 \r\nL 65.09375 72.90625 \r\nL 28.90625 38.921875 \r\nL 67.671875 0 \r\nL 54.6875 0 \r\nL 19.671875 35.109375 \r\nL 19.671875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-75\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-75\"/>\r\n       <use x=\"65.576172\" xlink:href=\"#DejaVuSans-78\"/>\r\n       <use x=\"140.380859\" xlink:href=\"#DejaVuSans-78\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"279.205313\" xlink:href=\"#m3bb40d583f\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- RF -->\r\n      <g transform=\"translate(272.855313 254.356563)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 9.8125 72.90625 \r\nL 51.703125 72.90625 \r\nL 51.703125 64.59375 \r\nL 19.671875 64.59375 \r\nL 19.671875 43.109375 \r\nL 48.578125 43.109375 \r\nL 48.578125 34.8125 \r\nL 19.671875 34.8125 \r\nL 19.671875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-70\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-82\"/>\r\n       <use x=\"69.482422\" xlink:href=\"#DejaVuSans-70\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"346.165313\" xlink:href=\"#m3bb40d583f\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- SVR -->\r\n      <g transform=\"translate(336.096563 254.356563)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 53.515625 70.515625 \r\nL 53.515625 60.890625 \r\nQ 47.90625 63.578125 42.921875 64.890625 \r\nQ 37.9375 66.21875 33.296875 66.21875 \r\nQ 25.25 66.21875 20.875 63.09375 \r\nQ 16.5 59.96875 16.5 54.203125 \r\nQ 16.5 49.359375 19.40625 46.890625 \r\nQ 22.3125 44.4375 30.421875 42.921875 \r\nL 36.375 41.703125 \r\nQ 47.40625 39.59375 52.65625 34.296875 \r\nQ 57.90625 29 57.90625 20.125 \r\nQ 57.90625 9.515625 50.796875 4.046875 \r\nQ 43.703125 -1.421875 29.984375 -1.421875 \r\nQ 24.8125 -1.421875 18.96875 -0.25 \r\nQ 13.140625 0.921875 6.890625 3.21875 \r\nL 6.890625 13.375 \r\nQ 12.890625 10.015625 18.65625 8.296875 \r\nQ 24.421875 6.59375 29.984375 6.59375 \r\nQ 38.421875 6.59375 43.015625 9.90625 \r\nQ 47.609375 13.234375 47.609375 19.390625 \r\nQ 47.609375 24.75 44.3125 27.78125 \r\nQ 41.015625 30.8125 33.5 32.328125 \r\nL 27.484375 33.5 \r\nQ 16.453125 35.6875 11.515625 40.375 \r\nQ 6.59375 45.0625 6.59375 53.421875 \r\nQ 6.59375 63.09375 13.40625 68.65625 \r\nQ 20.21875 74.21875 32.171875 74.21875 \r\nQ 37.3125 74.21875 42.625 73.28125 \r\nQ 47.953125 72.359375 53.515625 70.515625 \r\nz\r\n\" id=\"DejaVuSans-83\"/>\r\n        <path d=\"M 28.609375 0 \r\nL 0.78125 72.90625 \r\nL 11.078125 72.90625 \r\nL 34.1875 11.53125 \r\nL 57.328125 72.90625 \r\nL 67.578125 72.90625 \r\nL 39.796875 0 \r\nz\r\n\" id=\"DejaVuSans-86\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-83\"/>\r\n       <use x=\"63.476562\" xlink:href=\"#DejaVuSans-86\"/>\r\n       <use x=\"131.884766\" xlink:href=\"#DejaVuSans-82\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_6\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m9dcddce934\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#m9dcddce934\" y=\"210.107216\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 0.04 -->\r\n      <g transform=\"translate(7.2 213.906435)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.59375 35.5 \r\nL 73.1875 35.5 \r\nL 73.1875 27.203125 \r\nL 10.59375 27.203125 \r\nz\r\n\" id=\"DejaVuSans-8722\"/>\r\n        <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n        <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n        <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-8722\"/>\r\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"242.822266\" xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#m9dcddce934\" y=\"170.57267\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0.02 -->\r\n      <g transform=\"translate(7.2 174.371889)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-8722\"/>\r\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"242.822266\" xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#m9dcddce934\" y=\"131.038125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 0.00 -->\r\n      <g transform=\"translate(15.579688 134.837344)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#m9dcddce934\" y=\"91.50358\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0.02 -->\r\n      <g transform=\"translate(15.579688 95.302798)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#m9dcddce934\" y=\"51.969034\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.04 -->\r\n      <g transform=\"translate(15.579688 55.768253)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_11\">\r\n    <path clip-path=\"url(#p60b97bdd26)\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\r\n   </g>\r\n   <g id=\"line2d_12\">\r\n    <path clip-path=\"url(#p60b97bdd26)\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\r\n   </g>\r\n   <g id=\"line2d_13\">\r\n    <path clip-path=\"url(#p60b97bdd26)\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\r\n   </g>\r\n   <g id=\"line2d_14\">\r\n    <path clip-path=\"url(#p60b97bdd26)\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\r\n   </g>\r\n   <g id=\"line2d_15\">\r\n    <path clip-path=\"url(#p60b97bdd26)\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\r\n   </g>\r\n   <g id=\"line2d_16\"/>\r\n   <g id=\"line2d_17\">\r\n    <path clip-path=\"url(#p60b97bdd26)\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\r\n   </g>\r\n   <g id=\"line2d_18\">\r\n    <path clip-path=\"url(#p60b97bdd26)\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\r\n   </g>\r\n   <g id=\"line2d_19\">\r\n    <path clip-path=\"url(#p60b97bdd26)\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\r\n   </g>\r\n   <g id=\"line2d_20\">\r\n    <path clip-path=\"url(#p60b97bdd26)\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\r\n   </g>\r\n   <g id=\"line2d_21\">\r\n    <path clip-path=\"url(#p60b97bdd26)\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\r\n   </g>\r\n   <g id=\"line2d_22\"/>\r\n   <g id=\"line2d_23\">\r\n    <path clip-path=\"url(#p60b97bdd26)\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\r\n   </g>\r\n   <g id=\"line2d_24\">\r\n    <path clip-path=\"url(#p60b97bdd26)\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\r\n   </g>\r\n   <g id=\"line2d_25\">\r\n    <path clip-path=\"url(#p60b97bdd26)\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\r\n   </g>\r\n   <g id=\"line2d_26\">\r\n    <path clip-path=\"url(#p60b97bdd26)\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\r\n   </g>\r\n   <g id=\"line2d_27\">\r\n    <path clip-path=\"url(#p60b97bdd26)\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\r\n   </g>\r\n   <g id=\"line2d_28\"/>\r\n   <g id=\"line2d_29\">\r\n    <path clip-path=\"url(#p60b97bdd26)\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\r\n   </g>\r\n   <g id=\"line2d_30\">\r\n    <path clip-path=\"url(#p60b97bdd26)\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\r\n   </g>\r\n   <g id=\"line2d_31\">\r\n    <path clip-path=\"url(#p60b97bdd26)\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\r\n   </g>\r\n   <g id=\"line2d_32\">\r\n    <path clip-path=\"url(#p60b97bdd26)\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\r\n   </g>\r\n   <g id=\"line2d_33\">\r\n    <path clip-path=\"url(#p60b97bdd26)\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\r\n   </g>\r\n   <g id=\"line2d_34\"/>\r\n   <g id=\"line2d_35\">\r\n    <path clip-path=\"url(#p60b97bdd26)\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\r\n   </g>\r\n   <g id=\"line2d_36\">\r\n    <path clip-path=\"url(#p60b97bdd26)\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\r\n   </g>\r\n   <g id=\"line2d_37\">\r\n    <path clip-path=\"url(#p60b97bdd26)\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\r\n   </g>\r\n   <g id=\"line2d_38\">\r\n    <path clip-path=\"url(#p60b97bdd26)\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\r\n   </g>\r\n   <g id=\"line2d_39\">\r\n    <path clip-path=\"url(#p60b97bdd26)\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\r\n   </g>\r\n   <g id=\"line2d_40\"/>\r\n   <g id=\"line2d_41\">\r\n    <path clip-path=\"url(#p60b97bdd26)\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;\"/>\r\n   </g>\r\n   <g id=\"line2d_42\">\r\n    <path clip-path=\"url(#p60b97bdd26)\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;\"/>\r\n   </g>\r\n   <g id=\"line2d_43\">\r\n    <path clip-path=\"url(#p60b97bdd26)\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;\"/>\r\n   </g>\r\n   <g id=\"line2d_44\">\r\n    <path clip-path=\"url(#p60b97bdd26)\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;\"/>\r\n   </g>\r\n   <g id=\"line2d_45\">\r\n    <path clip-path=\"url(#p60b97bdd26)\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 44.845313 239.758125 \r\nL 44.845313 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 379.645313 239.758125 \r\nL 379.645313 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 44.845313 239.758125 \r\nL 379.645313 239.758125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 44.845313 22.318125 \r\nL 379.645313 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_11\">\r\n    <!-- Algorithm Comparison -->\r\n    <g transform=\"translate(145.030313 16.318125)scale(0.12 -0.12)\">\r\n     <defs>\r\n      <path d=\"M 34.1875 63.1875 \r\nL 20.796875 26.90625 \r\nL 47.609375 26.90625 \r\nz\r\nM 28.609375 72.90625 \r\nL 39.796875 72.90625 \r\nL 67.578125 0 \r\nL 57.328125 0 \r\nL 50.6875 18.703125 \r\nL 17.828125 18.703125 \r\nL 11.1875 0 \r\nL 0.78125 0 \r\nz\r\n\" id=\"DejaVuSans-65\"/>\r\n      <path d=\"M 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\n\" id=\"DejaVuSans-108\"/>\r\n      <path d=\"M 45.40625 27.984375 \r\nQ 45.40625 37.75 41.375 43.109375 \r\nQ 37.359375 48.484375 30.078125 48.484375 \r\nQ 22.859375 48.484375 18.828125 43.109375 \r\nQ 14.796875 37.75 14.796875 27.984375 \r\nQ 14.796875 18.265625 18.828125 12.890625 \r\nQ 22.859375 7.515625 30.078125 7.515625 \r\nQ 37.359375 7.515625 41.375 12.890625 \r\nQ 45.40625 18.265625 45.40625 27.984375 \r\nz\r\nM 54.390625 6.78125 \r\nQ 54.390625 -7.171875 48.1875 -13.984375 \r\nQ 42 -20.796875 29.203125 -20.796875 \r\nQ 24.46875 -20.796875 20.265625 -20.09375 \r\nQ 16.0625 -19.390625 12.109375 -17.921875 \r\nL 12.109375 -9.1875 \r\nQ 16.0625 -11.328125 19.921875 -12.34375 \r\nQ 23.78125 -13.375 27.78125 -13.375 \r\nQ 36.625 -13.375 41.015625 -8.765625 \r\nQ 45.40625 -4.15625 45.40625 5.171875 \r\nL 45.40625 9.625 \r\nQ 42.625 4.78125 38.28125 2.390625 \r\nQ 33.9375 0 27.875 0 \r\nQ 17.828125 0 11.671875 7.65625 \r\nQ 5.515625 15.328125 5.515625 27.984375 \r\nQ 5.515625 40.671875 11.671875 48.328125 \r\nQ 17.828125 56 27.875 56 \r\nQ 33.9375 56 38.28125 53.609375 \r\nQ 42.625 51.21875 45.40625 46.390625 \r\nL 45.40625 54.6875 \r\nL 54.390625 54.6875 \r\nz\r\n\" id=\"DejaVuSans-103\"/>\r\n      <path d=\"M 30.609375 48.390625 \r\nQ 23.390625 48.390625 19.1875 42.75 \r\nQ 14.984375 37.109375 14.984375 27.296875 \r\nQ 14.984375 17.484375 19.15625 11.84375 \r\nQ 23.34375 6.203125 30.609375 6.203125 \r\nQ 37.796875 6.203125 41.984375 11.859375 \r\nQ 46.1875 17.53125 46.1875 27.296875 \r\nQ 46.1875 37.015625 41.984375 42.703125 \r\nQ 37.796875 48.390625 30.609375 48.390625 \r\nz\r\nM 30.609375 56 \r\nQ 42.328125 56 49.015625 48.375 \r\nQ 55.71875 40.765625 55.71875 27.296875 \r\nQ 55.71875 13.875 49.015625 6.21875 \r\nQ 42.328125 -1.421875 30.609375 -1.421875 \r\nQ 18.84375 -1.421875 12.171875 6.21875 \r\nQ 5.515625 13.875 5.515625 27.296875 \r\nQ 5.515625 40.765625 12.171875 48.375 \r\nQ 18.84375 56 30.609375 56 \r\nz\r\n\" id=\"DejaVuSans-111\"/>\r\n      <path d=\"M 41.109375 46.296875 \r\nQ 39.59375 47.171875 37.8125 47.578125 \r\nQ 36.03125 48 33.890625 48 \r\nQ 26.265625 48 22.1875 43.046875 \r\nQ 18.109375 38.09375 18.109375 28.8125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 20.953125 51.171875 25.484375 53.578125 \r\nQ 30.03125 56 36.53125 56 \r\nQ 37.453125 56 38.578125 55.875 \r\nQ 39.703125 55.765625 41.0625 55.515625 \r\nz\r\n\" id=\"DejaVuSans-114\"/>\r\n      <path d=\"M 9.421875 54.6875 \r\nL 18.40625 54.6875 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\nM 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 64.59375 \r\nL 9.421875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-105\"/>\r\n      <path d=\"M 18.3125 70.21875 \r\nL 18.3125 54.6875 \r\nL 36.8125 54.6875 \r\nL 36.8125 47.703125 \r\nL 18.3125 47.703125 \r\nL 18.3125 18.015625 \r\nQ 18.3125 11.328125 20.140625 9.421875 \r\nQ 21.96875 7.515625 27.59375 7.515625 \r\nL 36.8125 7.515625 \r\nL 36.8125 0 \r\nL 27.59375 0 \r\nQ 17.1875 0 13.234375 3.875 \r\nQ 9.28125 7.765625 9.28125 18.015625 \r\nL 9.28125 47.703125 \r\nL 2.6875 47.703125 \r\nL 2.6875 54.6875 \r\nL 9.28125 54.6875 \r\nL 9.28125 70.21875 \r\nz\r\n\" id=\"DejaVuSans-116\"/>\r\n      <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 75.984375 \r\nL 18.109375 75.984375 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-104\"/>\r\n      <path d=\"M 52 44.1875 \r\nQ 55.375 50.25 60.0625 53.125 \r\nQ 64.75 56 71.09375 56 \r\nQ 79.640625 56 84.28125 50.015625 \r\nQ 88.921875 44.046875 88.921875 33.015625 \r\nL 88.921875 0 \r\nL 79.890625 0 \r\nL 79.890625 32.71875 \r\nQ 79.890625 40.578125 77.09375 44.375 \r\nQ 74.3125 48.1875 68.609375 48.1875 \r\nQ 61.625 48.1875 57.5625 43.546875 \r\nQ 53.515625 38.921875 53.515625 30.90625 \r\nL 53.515625 0 \r\nL 44.484375 0 \r\nL 44.484375 32.71875 \r\nQ 44.484375 40.625 41.703125 44.40625 \r\nQ 38.921875 48.1875 33.109375 48.1875 \r\nQ 26.21875 48.1875 22.15625 43.53125 \r\nQ 18.109375 38.875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.1875 51.21875 25.484375 53.609375 \r\nQ 29.78125 56 35.6875 56 \r\nQ 41.65625 56 45.828125 52.96875 \r\nQ 50 49.953125 52 44.1875 \r\nz\r\n\" id=\"DejaVuSans-109\"/>\r\n      <path id=\"DejaVuSans-32\"/>\r\n      <path d=\"M 64.40625 67.28125 \r\nL 64.40625 56.890625 \r\nQ 59.421875 61.53125 53.78125 63.8125 \r\nQ 48.140625 66.109375 41.796875 66.109375 \r\nQ 29.296875 66.109375 22.65625 58.46875 \r\nQ 16.015625 50.828125 16.015625 36.375 \r\nQ 16.015625 21.96875 22.65625 14.328125 \r\nQ 29.296875 6.6875 41.796875 6.6875 \r\nQ 48.140625 6.6875 53.78125 8.984375 \r\nQ 59.421875 11.28125 64.40625 15.921875 \r\nL 64.40625 5.609375 \r\nQ 59.234375 2.09375 53.4375 0.328125 \r\nQ 47.65625 -1.421875 41.21875 -1.421875 \r\nQ 24.65625 -1.421875 15.125 8.703125 \r\nQ 5.609375 18.84375 5.609375 36.375 \r\nQ 5.609375 53.953125 15.125 64.078125 \r\nQ 24.65625 74.21875 41.21875 74.21875 \r\nQ 47.75 74.21875 53.53125 72.484375 \r\nQ 59.328125 70.75 64.40625 67.28125 \r\nz\r\n\" id=\"DejaVuSans-67\"/>\r\n      <path d=\"M 18.109375 8.203125 \r\nL 18.109375 -20.796875 \r\nL 9.078125 -20.796875 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.390625 \r\nQ 20.953125 51.265625 25.265625 53.625 \r\nQ 29.59375 56 35.59375 56 \r\nQ 45.5625 56 51.78125 48.09375 \r\nQ 58.015625 40.1875 58.015625 27.296875 \r\nQ 58.015625 14.40625 51.78125 6.484375 \r\nQ 45.5625 -1.421875 35.59375 -1.421875 \r\nQ 29.59375 -1.421875 25.265625 0.953125 \r\nQ 20.953125 3.328125 18.109375 8.203125 \r\nz\r\nM 48.6875 27.296875 \r\nQ 48.6875 37.203125 44.609375 42.84375 \r\nQ 40.53125 48.484375 33.40625 48.484375 \r\nQ 26.265625 48.484375 22.1875 42.84375 \r\nQ 18.109375 37.203125 18.109375 27.296875 \r\nQ 18.109375 17.390625 22.1875 11.75 \r\nQ 26.265625 6.109375 33.40625 6.109375 \r\nQ 40.53125 6.109375 44.609375 11.75 \r\nQ 48.6875 17.390625 48.6875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-112\"/>\r\n      <path d=\"M 34.28125 27.484375 \r\nQ 23.390625 27.484375 19.1875 25 \r\nQ 14.984375 22.515625 14.984375 16.5 \r\nQ 14.984375 11.71875 18.140625 8.90625 \r\nQ 21.296875 6.109375 26.703125 6.109375 \r\nQ 34.1875 6.109375 38.703125 11.40625 \r\nQ 43.21875 16.703125 43.21875 25.484375 \r\nL 43.21875 27.484375 \r\nz\r\nM 52.203125 31.203125 \r\nL 52.203125 0 \r\nL 43.21875 0 \r\nL 43.21875 8.296875 \r\nQ 40.140625 3.328125 35.546875 0.953125 \r\nQ 30.953125 -1.421875 24.3125 -1.421875 \r\nQ 15.921875 -1.421875 10.953125 3.296875 \r\nQ 6 8.015625 6 15.921875 \r\nQ 6 25.140625 12.171875 29.828125 \r\nQ 18.359375 34.515625 30.609375 34.515625 \r\nL 43.21875 34.515625 \r\nL 43.21875 35.40625 \r\nQ 43.21875 41.609375 39.140625 45 \r\nQ 35.0625 48.390625 27.6875 48.390625 \r\nQ 23 48.390625 18.546875 47.265625 \r\nQ 14.109375 46.140625 10.015625 43.890625 \r\nL 10.015625 52.203125 \r\nQ 14.9375 54.109375 19.578125 55.046875 \r\nQ 24.21875 56 28.609375 56 \r\nQ 40.484375 56 46.34375 49.84375 \r\nQ 52.203125 43.703125 52.203125 31.203125 \r\nz\r\n\" id=\"DejaVuSans-97\"/>\r\n      <path d=\"M 44.28125 53.078125 \r\nL 44.28125 44.578125 \r\nQ 40.484375 46.53125 36.375 47.5 \r\nQ 32.28125 48.484375 27.875 48.484375 \r\nQ 21.1875 48.484375 17.84375 46.4375 \r\nQ 14.5 44.390625 14.5 40.28125 \r\nQ 14.5 37.15625 16.890625 35.375 \r\nQ 19.28125 33.59375 26.515625 31.984375 \r\nL 29.59375 31.296875 \r\nQ 39.15625 29.25 43.1875 25.515625 \r\nQ 47.21875 21.78125 47.21875 15.09375 \r\nQ 47.21875 7.46875 41.1875 3.015625 \r\nQ 35.15625 -1.421875 24.609375 -1.421875 \r\nQ 20.21875 -1.421875 15.453125 -0.5625 \r\nQ 10.6875 0.296875 5.421875 2 \r\nL 5.421875 11.28125 \r\nQ 10.40625 8.6875 15.234375 7.390625 \r\nQ 20.0625 6.109375 24.8125 6.109375 \r\nQ 31.15625 6.109375 34.5625 8.28125 \r\nQ 37.984375 10.453125 37.984375 14.40625 \r\nQ 37.984375 18.0625 35.515625 20.015625 \r\nQ 33.0625 21.96875 24.703125 23.78125 \r\nL 21.578125 24.515625 \r\nQ 13.234375 26.265625 9.515625 29.90625 \r\nQ 5.8125 33.546875 5.8125 39.890625 \r\nQ 5.8125 47.609375 11.28125 51.796875 \r\nQ 16.75 56 26.8125 56 \r\nQ 31.78125 56 36.171875 55.265625 \r\nQ 40.578125 54.546875 44.28125 53.078125 \r\nz\r\n\" id=\"DejaVuSans-115\"/>\r\n      <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-110\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-65\"/>\r\n     <use x=\"68.408203\" xlink:href=\"#DejaVuSans-108\"/>\r\n     <use x=\"96.191406\" xlink:href=\"#DejaVuSans-103\"/>\r\n     <use x=\"159.667969\" xlink:href=\"#DejaVuSans-111\"/>\r\n     <use x=\"220.849609\" xlink:href=\"#DejaVuSans-114\"/>\r\n     <use x=\"261.962891\" xlink:href=\"#DejaVuSans-105\"/>\r\n     <use x=\"289.746094\" xlink:href=\"#DejaVuSans-116\"/>\r\n     <use x=\"328.955078\" xlink:href=\"#DejaVuSans-104\"/>\r\n     <use x=\"392.333984\" xlink:href=\"#DejaVuSans-109\"/>\r\n     <use x=\"489.746094\" xlink:href=\"#DejaVuSans-32\"/>\r\n     <use x=\"521.533203\" xlink:href=\"#DejaVuSans-67\"/>\r\n     <use x=\"591.357422\" xlink:href=\"#DejaVuSans-111\"/>\r\n     <use x=\"652.539062\" xlink:href=\"#DejaVuSans-109\"/>\r\n     <use x=\"749.951172\" xlink:href=\"#DejaVuSans-112\"/>\r\n     <use x=\"813.427734\" xlink:href=\"#DejaVuSans-97\"/>\r\n     <use x=\"874.707031\" xlink:href=\"#DejaVuSans-114\"/>\r\n     <use x=\"915.820312\" xlink:href=\"#DejaVuSans-105\"/>\r\n     <use x=\"943.603516\" xlink:href=\"#DejaVuSans-115\"/>\r\n     <use x=\"995.703125\" xlink:href=\"#DejaVuSans-111\"/>\r\n     <use x=\"1056.884766\" xlink:href=\"#DejaVuSans-110\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p60b97bdd26\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"44.845313\" y=\"22.318125\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "673e9025f603f9e604ea6940cdd6a5362fe8df31b66759019337fbfba982bc05"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}